{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "sWAEJFFn88TA"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "# append the filepath to where torch is installed\n",
    "sys.path.append('/home/millerm/.local/lib/python3.10/site-packages')\n",
    "# sys.path.append('/home/username/.local/lib/python3.10/site-packages')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t-rds88B5jvV",
    "outputId": "ff42b39e-872f-42e8-d02f-be27222b523a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 0., ..., 1., 1., 1.])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_name = \"ml4h_data/project2/project2_TS_input/ptbdb_train.csv\"\n",
    "df_train = pd.read_csv(file_name,header=None)\n",
    "x_train = df_train.iloc[:, df_train.columns != 187]\n",
    "x_train = x_train.values.reshape(-1, 1, 187)\n",
    "train_target = df_train.iloc[:, 187]\n",
    "train_target = train_target.values\n",
    "train_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z8iZ3RvsNVkc",
    "outputId": "0eb494c4-f2d9-404b-c04b-aa19258e51df"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 0., ..., 1., 1., 0.])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_name = \"ml4h_data/project2/project2_TS_input/ptbdb_test.csv\"\n",
    "df_test = pd.read_csv(file_name,header=None)\n",
    "x_test = df_test.iloc[:, df_test.columns != 187]\n",
    "x_test = x_test.values.reshape(-1, 1, 187)\n",
    "test_target = df_test.iloc[:, 187]\n",
    "test_target = test_target.values\n",
    "test_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from setsloaders import create_datasets, create_loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "NBYbP0FLOcVr"
   },
   "outputs": [],
   "source": [
    "datasets = create_datasets(x_train, x_test, train_target, test_target, seed=123)\n",
    "trn_dl, val_dl, tst_dl = create_loaders(datasets, bs=256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vanilla CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_channels = 1\n",
    "num_classes = 2\n",
    "output_size = 2\n",
    "train_loader = trn_dl\n",
    "test_loader = tst_dl\n",
    "num_epochs = 30\n",
    "learning_rate = 0.005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 0.42196783423423767\n",
      "Epoch: 1, Loss: 0.26996707916259766\n",
      "Epoch: 2, Loss: 0.3202950954437256\n",
      "Epoch: 3, Loss: 0.26360201835632324\n",
      "Epoch: 4, Loss: 0.2283637672662735\n",
      "Epoch: 5, Loss: 0.1429937779903412\n",
      "Epoch: 6, Loss: 0.14124779403209686\n",
      "Epoch: 7, Loss: 0.10368941724300385\n",
      "Epoch: 8, Loss: 0.08037424087524414\n",
      "Epoch: 9, Loss: 0.07947560399770737\n",
      "Epoch: 10, Loss: 0.15870201587677002\n",
      "Epoch: 11, Loss: 0.10222574323415756\n",
      "Epoch: 12, Loss: 0.07381618767976761\n",
      "Epoch: 13, Loss: 0.07818073779344559\n",
      "Epoch: 14, Loss: 0.04714014753699303\n",
      "Epoch: 15, Loss: 0.0847485288977623\n",
      "Epoch: 16, Loss: 0.034282080829143524\n",
      "Epoch: 17, Loss: 0.05068464204668999\n",
      "Epoch: 18, Loss: 0.07417630404233932\n",
      "Epoch: 19, Loss: 0.03859033063054085\n",
      "Epoch: 20, Loss: 0.03321503847837448\n",
      "Epoch: 21, Loss: 0.01942056231200695\n",
      "Epoch: 22, Loss: 0.0347738116979599\n",
      "Epoch: 23, Loss: 0.041800256818532944\n",
      "Epoch: 24, Loss: 0.020079998299479485\n",
      "Epoch: 25, Loss: 0.023609157651662827\n",
      "Epoch: 26, Loss: 0.0044312928803265095\n",
      "Epoch: 27, Loss: 0.004649407230317593\n",
      "Epoch: 28, Loss: 0.004091743379831314\n",
      "Epoch: 29, Loss: 0.005066143814474344\n",
      "Accuracy: 98.28%\n"
     ]
    }
   ],
   "source": [
    "class cnn(nn.Module):\n",
    "    def __init__(self, input_channels, num_classes):\n",
    "        super(cnn, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=input_channels, out_channels=64, kernel_size=3)\n",
    "        self.conv2 = nn.Conv1d(in_channels=64, out_channels=128, kernel_size=3)\n",
    "        self.conv3 = nn.Conv1d(in_channels=128, out_channels=256, kernel_size=3)\n",
    "        self.fc1 = nn.Linear(5376, 128)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.pool = nn.MaxPool1d(kernel_size=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.relu(self.conv3(x))\n",
    "        x = self.pool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "model = cnn(input_channels, num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f\"Epoch: {epoch}, Loss: {loss}\")\n",
    "        \n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    print('Accuracy: {:.2f}%'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.99\n",
      "Recall: 0.99\n",
      "F1-Score: 0.99\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "predictions = []\n",
    "ground_truth = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        predictions.extend(predicted.cpu().numpy())\n",
    "        ground_truth.extend(labels.cpu().numpy())\n",
    "\n",
    "predictions = np.array(predictions)\n",
    "ground_truth = np.array(ground_truth)\n",
    "\n",
    "precision = precision_score(ground_truth, predictions, average='binary')\n",
    "recall = recall_score(ground_truth, predictions, average='binary')\n",
    "f1 = (2*precision*recall)/(precision+recall)\n",
    "\n",
    "print('Precision: {:.2f}'.format(precision))\n",
    "print('Recall: {:.2f}'.format(recall))\n",
    "print('F1-Score: {:.2f}'.format(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"models/vanillacnn.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Residual Blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_channels = 1\n",
    "num_classes = 2\n",
    "train_loader = trn_dl\n",
    "test_loader = tst_dl\n",
    "num_epochs = 30\n",
    "learning_rate = 0.005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels, out_channels, kernel_size, padding=1)\n",
    "        self.conv2 = nn.Conv1d(out_channels, out_channels, kernel_size, padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.relu(self.conv1(x))\n",
    "        out = self.conv2(out)\n",
    "        out += residual  # Residual connection\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "class rescnn(nn.Module):\n",
    "    def __init__(self, input_channels, num_classes):\n",
    "        super(rescnn, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(input_channels, 64, kernel_size=3)\n",
    "        self.residual_block1 = ResidualBlock(64, 64, kernel_size=3)\n",
    "        self.pool1 = nn.MaxPool1d(kernel_size=2)\n",
    "        self.conv2 = nn.Conv1d(64, 128, kernel_size=3)\n",
    "        self.residual_block2 = ResidualBlock(128, 128, kernel_size=3)\n",
    "        self.pool2 = nn.MaxPool1d(kernel_size=2)\n",
    "        self.conv3 = nn.Conv1d(128, 256, kernel_size=3)\n",
    "        self.residual_block3 = ResidualBlock(256, 256, kernel_size=3)\n",
    "        self.pool3 = nn.MaxPool1d(kernel_size=2)\n",
    "        self.fc1 = nn.Linear(5376, 128)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.residual_block1(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.residual_block2(x)\n",
    "        x = self.pool2(x)\n",
    "        x = self.relu(self.conv3(x))\n",
    "        x = self.residual_block3(x)\n",
    "        x = self.pool3(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 0.3714563846588135\n",
      "Epoch: 1, Loss: 0.2989402115345001\n",
      "Epoch: 2, Loss: 0.31668052077293396\n",
      "Epoch: 3, Loss: 0.1769210547208786\n",
      "Epoch: 4, Loss: 0.2206125557422638\n",
      "Epoch: 5, Loss: 0.19620147347450256\n",
      "Epoch: 6, Loss: 0.1541152447462082\n",
      "Epoch: 7, Loss: 0.10125810652971268\n",
      "Epoch: 8, Loss: 0.08323320001363754\n",
      "Epoch: 9, Loss: 0.030131559818983078\n",
      "Epoch: 10, Loss: 0.09060701727867126\n",
      "Epoch: 11, Loss: 0.10514943301677704\n",
      "Epoch: 12, Loss: 0.029458578675985336\n",
      "Epoch: 13, Loss: 0.06162691116333008\n",
      "Epoch: 14, Loss: 0.04238803684711456\n",
      "Epoch: 15, Loss: 0.006754663307219744\n",
      "Epoch: 16, Loss: 0.016100751236081123\n",
      "Epoch: 17, Loss: 0.009632227011024952\n",
      "Epoch: 18, Loss: 0.017751645296812057\n",
      "Epoch: 19, Loss: 0.0230732224881649\n",
      "Epoch: 20, Loss: 0.007024645805358887\n",
      "Epoch: 21, Loss: 0.04222329333424568\n",
      "Epoch: 22, Loss: 0.010342000983655453\n",
      "Epoch: 23, Loss: 0.06625109910964966\n",
      "Epoch: 24, Loss: 0.01555738877505064\n",
      "Epoch: 25, Loss: 0.010984146036207676\n",
      "Epoch: 26, Loss: 0.0012418749975040555\n",
      "Epoch: 27, Loss: 0.010158395394682884\n",
      "Epoch: 28, Loss: 0.026707906275987625\n",
      "Epoch: 29, Loss: 0.015411495231091976\n",
      "Accuracy: 98.32%\n"
     ]
    }
   ],
   "source": [
    "model = rescnn(input_channels, num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f\"Epoch: {epoch}, Loss: {loss}\")\n",
    "        \n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    print('Accuracy: {:.2f}%'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.99\n",
      "Recall: 0.99\n",
      "F1-Score: 0.99\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "predictions = []\n",
    "ground_truth = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        predictions.extend(predicted.cpu().numpy())\n",
    "        ground_truth.extend(labels.cpu().numpy())\n",
    "\n",
    "predictions = np.array(predictions)\n",
    "ground_truth = np.array(ground_truth)\n",
    "\n",
    "precision = precision_score(ground_truth, predictions, average='binary')\n",
    "recall = recall_score(ground_truth, predictions, average='binary')\n",
    "f1 = (2*precision*recall)/(precision+recall)\n",
    "\n",
    "print('Precision: {:.2f}'.format(precision))\n",
    "print('Recall: {:.2f}'.format(recall))\n",
    "print('F1-Score: {:.2f}'.format(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"models/residualcnn.pth\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
