{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "sWAEJFFn88TA"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "# append the filepath to where torch is installed\n",
    "sys.path.append('/home/millerm/.local/lib/python3.10/site-packages')\n",
    "# sys.path.append('/home/username/.local/lib/python3.10/site-packages')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t-rds88B5jvV",
    "outputId": "ff42b39e-872f-42e8-d02f-be27222b523a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 0., ..., 1., 1., 1.])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_name = \"ml4h_data/project2/project2_TS_input/ptbdb_train.csv\"\n",
    "df_train = pd.read_csv(file_name,header=None)\n",
    "x_train = df_train.iloc[:, df_train.columns != 187]\n",
    "x_train = x_train.values.reshape(-1, 1, 187)\n",
    "train_target = df_train.iloc[:, 187]\n",
    "train_target = train_target.values\n",
    "train_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z8iZ3RvsNVkc",
    "outputId": "0eb494c4-f2d9-404b-c04b-aa19258e51df"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 0., ..., 1., 1., 0.])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_name = \"ml4h_data/project2/project2_TS_input/ptbdb_test.csv\"\n",
    "df_test = pd.read_csv(file_name,header=None)\n",
    "x_test = df_test.iloc[:, df_test.columns != 187]\n",
    "x_test = x_test.values.reshape(-1, 1, 187)\n",
    "test_target = df_test.iloc[:, 187]\n",
    "test_target = test_target.values\n",
    "test_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from setsloaders import create_datasets, create_loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "NBYbP0FLOcVr"
   },
   "outputs": [],
   "source": [
    "datasets = create_datasets(x_train, x_test, train_target, test_target, seed=123)\n",
    "trn_dl, val_dl, tst_dl = create_loaders(datasets, bs=256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vanilla CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_channels = 1\n",
    "num_classes = 2\n",
    "output_size = 2\n",
    "train_loader = trn_dl\n",
    "test_loader = tst_dl\n",
    "num_epochs = 30\n",
    "learning_rate = 0.005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 0.4388217628002167\n",
      "Epoch: 1, Loss: 0.39442265033721924\n",
      "Epoch: 2, Loss: 0.33628031611442566\n",
      "Epoch: 3, Loss: 0.23043236136436462\n",
      "Epoch: 4, Loss: 0.15206879377365112\n",
      "Epoch: 5, Loss: 0.10935600847005844\n",
      "Epoch: 6, Loss: 0.11535815894603729\n",
      "Epoch: 7, Loss: 0.11228644102811813\n",
      "Epoch: 8, Loss: 0.04675921052694321\n",
      "Epoch: 9, Loss: 0.089759960770607\n",
      "Epoch: 10, Loss: 0.0822092592716217\n",
      "Epoch: 11, Loss: 0.05096311494708061\n",
      "Epoch: 12, Loss: 0.06558927893638611\n",
      "Epoch: 13, Loss: 0.03052239678800106\n",
      "Epoch: 14, Loss: 0.02178395353257656\n",
      "Epoch: 15, Loss: 0.03614456206560135\n",
      "Epoch: 16, Loss: 0.007159082219004631\n",
      "Epoch: 17, Loss: 0.04260924085974693\n",
      "Epoch: 18, Loss: 0.01644989103078842\n",
      "Epoch: 19, Loss: 0.018730537965893745\n",
      "Epoch: 20, Loss: 0.024351218715310097\n",
      "Epoch: 21, Loss: 0.04006785899400711\n",
      "Epoch: 22, Loss: 0.026187248528003693\n",
      "Epoch: 23, Loss: 0.006945765111595392\n",
      "Epoch: 24, Loss: 0.013442585244774818\n",
      "Epoch: 25, Loss: 0.003205548506230116\n",
      "Epoch: 26, Loss: 0.003156254766508937\n",
      "Epoch: 27, Loss: 0.005729354452341795\n",
      "Epoch: 28, Loss: 0.004220135509967804\n",
      "Epoch: 29, Loss: 0.0007229447364807129\n",
      "Accuracy: 98.76%\n"
     ]
    }
   ],
   "source": [
    "class cnn(nn.Module):\n",
    "    def __init__(self, input_channels, num_classes):\n",
    "        super(cnn, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=input_channels, out_channels=64, kernel_size=3)\n",
    "        self.conv2 = nn.Conv1d(in_channels=64, out_channels=128, kernel_size=3)\n",
    "        self.conv3 = nn.Conv1d(in_channels=128, out_channels=256, kernel_size=3)\n",
    "        self.fc1 = nn.Linear(5376, 128)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.pool = nn.MaxPool1d(kernel_size=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.relu(self.conv3(x))\n",
    "        x = self.pool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "model = cnn(input_channels, num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f\"Epoch: {epoch}, Loss: {loss}\")\n",
    "        \n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    print('Accuracy: {:.2f}%'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.99\n",
      "Recall: 0.99\n",
      "F1-Score: 0.99\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "predictions = []\n",
    "ground_truth = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        predictions.extend(predicted.cpu().numpy())\n",
    "        ground_truth.extend(labels.cpu().numpy())\n",
    "\n",
    "predictions = np.array(predictions)\n",
    "ground_truth = np.array(ground_truth)\n",
    "\n",
    "precision = precision_score(ground_truth, predictions, average='binary')  # assuming binary classification\n",
    "recall = recall_score(ground_truth, predictions, average='binary')  # assuming binary classification\n",
    "f1 = (2*precision*recall)/(precision+recall)\n",
    "\n",
    "print('Precision: {:.2f}'.format(precision))\n",
    "print('Recall: {:.2f}'.format(recall))\n",
    "print('F1-Score: {:.2f}'.format(f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Residual Blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_channels = 1\n",
    "num_classes = 2\n",
    "train_loader = trn_dl\n",
    "test_loader = tst_dl\n",
    "num_epochs = 30\n",
    "learning_rate = 0.005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels, out_channels, kernel_size, padding=1)\n",
    "        self.conv2 = nn.Conv1d(out_channels, out_channels, kernel_size, padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.relu(self.conv1(x))\n",
    "        out = self.conv2(out)\n",
    "        out += residual  # Residual connection\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "class rescnn(nn.Module):\n",
    "    def __init__(self, input_channels, num_classes):\n",
    "        super(rescnn, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(input_channels, 64, kernel_size=3)\n",
    "        self.residual_block1 = ResidualBlock(64, 64, kernel_size=3)\n",
    "        self.pool1 = nn.MaxPool1d(kernel_size=2)\n",
    "        self.conv2 = nn.Conv1d(64, 128, kernel_size=3)\n",
    "        self.residual_block2 = ResidualBlock(128, 128, kernel_size=3)\n",
    "        self.pool2 = nn.MaxPool1d(kernel_size=2)\n",
    "        self.conv3 = nn.Conv1d(128, 256, kernel_size=3)\n",
    "        self.residual_block3 = ResidualBlock(256, 256, kernel_size=3)\n",
    "        self.pool3 = nn.MaxPool1d(kernel_size=2)\n",
    "        self.fc1 = nn.Linear(5376, 128)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.residual_block1(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.residual_block2(x)\n",
    "        x = self.pool2(x)\n",
    "        x = self.relu(self.conv3(x))\n",
    "        x = self.residual_block3(x)\n",
    "        x = self.pool3(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 0.3979777991771698\n",
      "Epoch: 1, Loss: 0.38194504380226135\n",
      "Epoch: 2, Loss: 0.40125879645347595\n",
      "Epoch: 3, Loss: 0.19134031236171722\n",
      "Epoch: 4, Loss: 0.1398007720708847\n",
      "Epoch: 5, Loss: 0.108409583568573\n",
      "Epoch: 6, Loss: 0.0878017470240593\n",
      "Epoch: 7, Loss: 0.15512025356292725\n",
      "Epoch: 8, Loss: 0.06042991578578949\n",
      "Epoch: 9, Loss: 0.10401635617017746\n",
      "Epoch: 10, Loss: 0.04419603571295738\n",
      "Epoch: 11, Loss: 0.04062766954302788\n",
      "Epoch: 12, Loss: 0.05520084127783775\n",
      "Epoch: 13, Loss: 0.10112343728542328\n",
      "Epoch: 14, Loss: 0.04387304186820984\n",
      "Epoch: 15, Loss: 0.05715956911444664\n",
      "Epoch: 16, Loss: 0.12227906286716461\n",
      "Epoch: 17, Loss: 0.019189991056919098\n",
      "Epoch: 18, Loss: 0.019750172272324562\n",
      "Epoch: 19, Loss: 0.019334880635142326\n",
      "Epoch: 20, Loss: 0.022977938875555992\n",
      "Epoch: 21, Loss: 0.006403555162250996\n",
      "Epoch: 22, Loss: 0.00873741414397955\n",
      "Epoch: 23, Loss: 0.03909185528755188\n",
      "Epoch: 24, Loss: 0.002602543216198683\n",
      "Epoch: 25, Loss: 0.043907877057790756\n",
      "Epoch: 26, Loss: 0.0070802513509988785\n",
      "Epoch: 27, Loss: 0.020138008520007133\n",
      "Epoch: 28, Loss: 0.0025962642394006252\n",
      "Epoch: 29, Loss: 0.0019891876727342606\n",
      "Accuracy: 98.66%\n"
     ]
    }
   ],
   "source": [
    "model = rescnn(input_channels, num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f\"Epoch: {epoch}, Loss: {loss}\")\n",
    "        \n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    print('Accuracy: {:.2f}%'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.99\n",
      "Recall: 0.99\n",
      "F1-Score: 0.99\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "predictions = []\n",
    "ground_truth = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        predictions.extend(predicted.cpu().numpy())\n",
    "        ground_truth.extend(labels.cpu().numpy())\n",
    "\n",
    "predictions = np.array(predictions)\n",
    "ground_truth = np.array(ground_truth)\n",
    "\n",
    "precision = precision_score(ground_truth, predictions, average='binary')  # assuming binary classification\n",
    "recall = recall_score(ground_truth, predictions, average='binary')  # assuming binary classification\n",
    "f1 = (2*precision*recall)/(precision+recall)\n",
    "\n",
    "print('Precision: {:.2f}'.format(precision))\n",
    "print('Recall: {:.2f}'.format(recall))\n",
    "print('F1-Score: {:.2f}'.format(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
