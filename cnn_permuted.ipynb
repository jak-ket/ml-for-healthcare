{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This notebooks fits the cnn on permuted labeles for task 2.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "from torchinfo import summary\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.transforms import Lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import VGG16_Weights\n",
    "model = torchvision.models.vgg16(weights=VGG16_Weights.DEFAULT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_wo_norm = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "dataset0_wo_norm = torchvision.datasets.ImageFolder(\"archive/chest_xray/chest_xray/train\", transform=trans_wo_norm)\n",
    "dataset1_wo_norm = torchvision.datasets.ImageFolder(\"archive/chest_xray/chest_xray/test\", transform=trans_wo_norm)\n",
    "dataset2_wo_norm = torchvision.datasets.ImageFolder(\"archive/chest_xray/chest_xray/val\", transform=trans_wo_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: tensor([0.5832, 0.5832, 0.5832])\n",
      "Standard deviation: tensor([0.1413, 0.1413, 0.1413])\n"
     ]
    }
   ],
   "source": [
    "mean0 = torch.zeros(3)\n",
    "std0 = torch.zeros(3)\n",
    "for img, _ in dataset0_wo_norm:\n",
    "    mean0 += img.mean(dim=(1, 2))\n",
    "    std0 += img.std(dim=(1, 2))\n",
    "\n",
    "mean0 /= len(dataset0_wo_norm)\n",
    "std0 /= len(dataset0_wo_norm)\n",
    "\n",
    "print(\"Mean:\", mean0)\n",
    "print(\"Standard deviation:\", std0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: tensor([0.5763, 0.5763, 0.5763])\n",
      "Standard deviation: tensor([0.1453, 0.1453, 0.1453])\n"
     ]
    }
   ],
   "source": [
    "mean1 = torch.zeros(3)\n",
    "std1 = torch.zeros(3)\n",
    "for img, _ in dataset1_wo_norm:\n",
    "    mean1 += img.mean(dim=(1, 2))\n",
    "    std1 += img.std(dim=(1, 2))\n",
    "\n",
    "mean1 /= len(dataset1_wo_norm)\n",
    "std1 /= len(dataset1_wo_norm)\n",
    "\n",
    "print(\"Mean:\", mean1)\n",
    "print(\"Standard deviation:\", std1)\n",
    "\n",
    "# Mean: tensor([0.5763, 0.5763, 0.5763])\n",
    "# Standard deviation: tensor([0.1453, 0.1453, 0.1453])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: tensor([0.6020, 0.6020, 0.6020])\n",
      "Standard deviation: tensor([0.1401, 0.1401, 0.1401])\n"
     ]
    }
   ],
   "source": [
    "mean2 = torch.zeros(3)\n",
    "std2 = torch.zeros(3)\n",
    "for img, _ in dataset2_wo_norm:\n",
    "    mean2 += img.mean(dim=(1, 2))\n",
    "    std2 += img.std(dim=(1, 2))\n",
    "\n",
    "mean2 /= len(dataset2_wo_norm)\n",
    "std2 /= len(dataset2_wo_norm)\n",
    "\n",
    "print(\"Mean:\", mean2)\n",
    "print(\"Standard deviation:\", std2)\n",
    "\n",
    "# Mean: tensor([0.6020, 0.6020, 0.6020])\n",
    "# Standard deviation: tensor([0.1401, 0.1401, 0.1401])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean0 =torch.tensor([0.5832, 0.5832, 0.5832])\n",
    "std0  =torch.tensor([0.1413, 0.1413, 0.1413])\n",
    "mean1 =torch.tensor([0.5763, 0.5763, 0.5763])\n",
    "std1  =torch.tensor([0.1453, 0.1453, 0.1453])\n",
    "mean2 =torch.tensor([0.6020, 0.6020, 0.6020])\n",
    "std2  =torch.tensor([0.1401, 0.1401, 0.1401])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_normalise_0 = transforms.Normalize(\n",
    "    mean=mean0,\n",
    "    std=std0\n",
    ")\n",
    "std_normalise_1 = transforms.Normalize(\n",
    "    mean=mean1,\n",
    "    std=std1\n",
    ")\n",
    "std_normalise_2 = transforms.Normalize(\n",
    "    mean=mean2,\n",
    "    std=std2\n",
    ")\n",
    "\n",
    "trans0 = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.Grayscale(num_output_channels=3),\n",
    "        transforms.ToTensor(),\n",
    "        std_normalise_0\n",
    "])\n",
    "trans1 = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.Grayscale(num_output_channels=3),\n",
    "        transforms.ToTensor(),\n",
    "        std_normalise_1\n",
    "])\n",
    "trans2 = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.Grayscale(num_output_channels=3),\n",
    "        transforms.ToTensor(),\n",
    "        std_normalise_2\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_0 = torchvision.datasets.ImageFolder(\"archive/chest_xray/chest_xray/train\", transform=trans0)\n",
    "dataset_1 = torchvision.datasets.ImageFolder(\"archive/chest_xray/chest_xray/test\", transform=trans1)\n",
    "dataset_2 = torchvision.datasets.ImageFolder(\"archive/chest_xray/chest_xray/val\", transform=trans2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing computations on device = cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): ReLU(inplace=True)\n",
       "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): ReLU(inplace=True)\n",
       "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (27): ReLU(inplace=True)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "print('Doing computations on device = {}'.format(device))\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.classifier = nn.Sequential(\n",
    "    torch.nn.Linear(25088,4096),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Dropout(0.5, inplace = False),\n",
    "    torch.nn.Linear(4096,1000),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Dropout(0.5, inplace = False),\n",
    "    torch.nn.Linear(1000,2)\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we define train and validation set randomly as the validation set provided is too small for meaningful results\n",
    "trainset, testset = torch.utils.data.random_split(dataset_0, [4999, len(dataset_0) - 4999])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Permuted lables train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lables = np.array([lable for _, lable in trainset.dataset.imgs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "lables = np.random.permutation(lables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (_,lable) in enumerate(trainset.dataset.imgs):\n",
    "    trainset.dataset.imgs[i] = (trainset.dataset.imgs[i][0], lables[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(trainset,batch_size=32)\n",
    "test_loader  = torch.utils.data.DataLoader(testset,batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_long(net,train_loader,test_loader,epochs=5,lr=0.001,optimizer=None,loss_fn = nn.NLLLoss(),print_freq=10):\n",
    "    optimizer = optimizer or torch.optim.Adam(net.parameters(),lr=lr)\n",
    "    for epoch in range(epochs):\n",
    "        net.train()\n",
    "        total_loss,acc,count = 0,0,0\n",
    "        for i, (features,labels) in enumerate(train_loader):\n",
    "            lbls = labels.long().to(default_device)\n",
    "            optimizer.zero_grad()\n",
    "            out = net(features.to(default_device))\n",
    "            loss = loss_fn(out,lbls)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss+=loss\n",
    "            _,predicted = torch.max(out,1)\n",
    "            acc+=(predicted==lbls).sum()\n",
    "            count+=len(labels)\n",
    "            if i%print_freq==0:\n",
    "                print(\"Epoch {}, minibatch {}: train acc = {}, train loss = {}\".format(epoch,i,acc.item()/count,total_loss.item()/count))\n",
    "        vl,va = validate(net,test_loader,loss_fn)\n",
    "        print(\"Epoch {} done, validation acc = {}, validation loss = {}\".format(epoch,va,vl))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(net, dataloader,loss_fn=nn.NLLLoss()):\n",
    "    net.eval()\n",
    "    count,acc,loss = 0,0,0\n",
    "    with torch.no_grad():\n",
    "        for features,labels in dataloader:\n",
    "            \n",
    "            lbls = labels.long().to(default_device)\n",
    "            out = net(features.to(default_device))\n",
    "            loss += loss_fn(out,lbls) \n",
    "            pred = torch.max(out,1)[1]\n",
    "            acc += (pred==lbls).sum()\n",
    "            count += len(labels)\n",
    "    return loss.item()/count, acc.item()/count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.features.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, minibatch 0: train acc = 0.4375, train loss = 0.021872468292713165\n",
      "Epoch 0, minibatch 90: train acc = 0.7366071428571429, train loss = 0.01886152828132713\n",
      "Epoch 0 done, validation acc = 0.7511520737327189, validation loss = 0.01841489510602116\n",
      "Epoch 1, minibatch 0: train acc = 0.78125, train loss = 0.016169628128409386\n",
      "Epoch 1, minibatch 90: train acc = 0.7421016483516484, train loss = 0.018096833438663692\n",
      "Epoch 1 done, validation acc = 0.7465437788018433, validation loss = 0.018533801153508198\n",
      "Epoch 2, minibatch 0: train acc = 0.75, train loss = 0.016182364895939827\n",
      "Epoch 2, minibatch 90: train acc = 0.7421016483516484, train loss = 0.017601776909042192\n",
      "Epoch 2 done, validation acc = 0.7603686635944701, validation loss = 0.018234041978686635\n",
      "Epoch 3, minibatch 0: train acc = 0.84375, train loss = 0.015077903866767883\n",
      "Epoch 3, minibatch 90: train acc = 0.7561813186813187, train loss = 0.016589298353090393\n",
      "Epoch 3 done, validation acc = 0.728110599078341, validation loss = 0.019706708494968677\n"
     ]
    }
   ],
   "source": [
    "default_device = device\n",
    "train_long(model,train_loader,test_loader,lr=0.00005,loss_fn=torch.nn.CrossEntropyLoss(),epochs=4,print_freq=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model,'models/model_permuted.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml4h",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
