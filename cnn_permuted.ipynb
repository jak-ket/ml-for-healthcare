{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This notebooks fits the cnn on permuted labeles for task 2.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(\"models/20_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_wo_norm = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "dataset0_wo_norm = torchvision.datasets.ImageFolder(\"archive/chest_xray/chest_xray/train\", transform=trans_wo_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: tensor([0.5832, 0.5832, 0.5832])\n",
      "Standard deviation: tensor([0.1413, 0.1413, 0.1413])\n"
     ]
    }
   ],
   "source": [
    "mean0 = torch.zeros(3)\n",
    "std0 = torch.zeros(3)\n",
    "for img, _ in dataset0_wo_norm:\n",
    "    mean0 += img.mean(dim=(1, 2))\n",
    "    std0 += img.std(dim=(1, 2))\n",
    "\n",
    "mean0 /= len(dataset0_wo_norm)\n",
    "std0 /= len(dataset0_wo_norm)\n",
    "\n",
    "print(\"Mean:\", mean0)\n",
    "print(\"Standard deviation:\", std0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean0 =torch.tensor([0.5832, 0.5832, 0.5832])\n",
    "std0  =torch.tensor([0.1413, 0.1413, 0.1413])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_normalise_0 = transforms.Normalize(\n",
    "    mean=mean0,\n",
    "    std=std0\n",
    ")\n",
    "\n",
    "trans0 = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.Grayscale(num_output_channels=3),\n",
    "        transforms.ToTensor(),\n",
    "        std_normalise_0\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_0 = torchvision.datasets.ImageFolder(\"archive/chest_xray/chest_xray/train\", transform=trans0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing computations on device = cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): ReLU(inplace=True)\n",
       "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): ReLU(inplace=True)\n",
       "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (27): ReLU(inplace=True)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU()\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (7): ReLU()\n",
       "    (8): Dropout(p=0.5, inplace=False)\n",
       "    (9): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (10): ReLU()\n",
       "    (11): Dropout(p=0.5, inplace=False)\n",
       "    (12): Linear(in_features=4096, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "print('Doing computations on device = {}'.format(device))\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we define train and validation set randomly as the validation set provided is too small for meaningful results\n",
    "trainset, testset = torch.utils.data.random_split(dataset_0, [4999, len(dataset_0) - 4999])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Permute lables of train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lables = np.array([lable for _, lable in trainset.dataset.imgs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "lables = np.random.permutation(lables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (_,lable) in enumerate(trainset.dataset.imgs):\n",
    "    trainset.dataset.imgs[i] = (trainset.dataset.imgs[i][0], lables[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(trainset,batch_size=32)\n",
    "test_loader  = torch.utils.data.DataLoader(testset,batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_long(net,train_loader,test_loader,epochs=5,lr=0.001,optimizer=None,loss_fn = nn.NLLLoss(),print_freq=10):\n",
    "    optimizer = optimizer or torch.optim.Adam(net.parameters(),lr=lr)\n",
    "    for epoch in range(epochs):\n",
    "        net.train()\n",
    "        total_loss,acc,count = 0,0,0\n",
    "        for i, (features,labels) in enumerate(train_loader):\n",
    "            lbls = labels.long().to(default_device)\n",
    "            optimizer.zero_grad()\n",
    "            out = net(features.to(default_device))\n",
    "            loss = loss_fn(out,lbls)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss+=loss\n",
    "            _,predicted = torch.max(out,1)\n",
    "            acc+=(predicted==lbls).sum()\n",
    "            count+=len(labels)\n",
    "            if i%print_freq==0:\n",
    "                print(\"Epoch {}, minibatch {}: train acc = {}, train loss = {}\".format(epoch,i,acc.item()/count,total_loss.item()/count))\n",
    "        vl,va = validate(net,test_loader,loss_fn)\n",
    "        print(\"Epoch {} done, validation acc = {}, validation loss = {}\".format(epoch,va,vl))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(net, dataloader,loss_fn=nn.NLLLoss()):\n",
    "    net.eval()\n",
    "    count,acc,loss = 0,0,0\n",
    "    with torch.no_grad():\n",
    "        for features,labels in dataloader:\n",
    "            \n",
    "            lbls = labels.long().to(default_device)\n",
    "            out = net(features.to(default_device))\n",
    "            loss += loss_fn(out,lbls) \n",
    "            pred = torch.max(out,1)[1]\n",
    "            acc += (pred==lbls).sum()\n",
    "            count += len(labels)\n",
    "    return loss.item()/count, acc.item()/count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.features.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, minibatch 0: train acc = 0.59375, train loss = 0.7303264141082764\n",
      "Epoch 0, minibatch 90: train acc = 0.7002060439560439, train loss = 0.049046060541173914\n",
      "Epoch 0 done, validation acc = 0.7511520737327189, validation loss = 0.01969623345933202\n",
      "Epoch 1, minibatch 0: train acc = 0.8125, train loss = 0.0173207838088274\n",
      "Epoch 1, minibatch 90: train acc = 0.7451923076923077, train loss = 0.018100403167389253\n",
      "Epoch 1 done, validation acc = 0.7511520737327189, validation loss = 0.019295123315626574\n",
      "Epoch 2, minibatch 0: train acc = 0.8125, train loss = 0.016510585322976112\n",
      "Epoch 2, minibatch 90: train acc = 0.7479395604395604, train loss = 0.01787801627274398\n",
      "Epoch 2 done, validation acc = 0.7511520737327189, validation loss = 0.01882407632291592\n",
      "Epoch 3, minibatch 0: train acc = 0.8125, train loss = 0.014752785675227642\n",
      "Epoch 3, minibatch 90: train acc = 0.75, train loss = 0.01741045647925073\n",
      "Epoch 3 done, validation acc = 0.7511520737327189, validation loss = 0.019676041493218065\n",
      "Epoch 4, minibatch 0: train acc = 0.71875, train loss = 0.01863112673163414\n",
      "Epoch 4, minibatch 90: train acc = 0.7486263736263736, train loss = 0.016915811287177788\n",
      "Epoch 4 done, validation acc = 0.7511520737327189, validation loss = 0.019347474322341005\n",
      "Epoch 5, minibatch 0: train acc = 0.71875, train loss = 0.0170748271048069\n",
      "Epoch 5, minibatch 90: train acc = 0.759271978021978, train loss = 0.01586577263507214\n",
      "Epoch 5 done, validation acc = 0.728110599078341, validation loss = 0.020104871916880804\n",
      "Epoch 6, minibatch 0: train acc = 0.75, train loss = 0.017748741433024406\n",
      "Epoch 6, minibatch 90: train acc = 0.78125, train loss = 0.014207118160122044\n",
      "Epoch 6 done, validation acc = 0.7373271889400922, validation loss = 0.020493116246939804\n",
      "Epoch 7, minibatch 0: train acc = 0.84375, train loss = 0.014509376138448715\n",
      "Epoch 7, minibatch 90: train acc = 0.8190247252747253, train loss = 0.012464597984984681\n",
      "Epoch 7 done, validation acc = 0.6036866359447005, validation loss = 0.0214302001460906\n",
      "Epoch 8, minibatch 0: train acc = 0.78125, train loss = 0.015614744275808334\n",
      "Epoch 8, minibatch 90: train acc = 0.8581730769230769, train loss = 0.01015878378689944\n",
      "Epoch 8 done, validation acc = 0.631336405529954, validation loss = 0.021744919262723438\n",
      "Epoch 9, minibatch 0: train acc = 0.875, train loss = 0.013811632990837097\n",
      "Epoch 9, minibatch 90: train acc = 0.9024725274725275, train loss = 0.007535194957649315\n",
      "Epoch 9 done, validation acc = 0.543778801843318, validation loss = 0.023880189464938258\n"
     ]
    }
   ],
   "source": [
    "default_device = device\n",
    "train_long(model,train_loader,test_loader,lr=0.00005,loss_fn=torch.nn.CrossEntropyLoss(),epochs=10,print_freq=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.022232620352195438, 0.9105821164232847)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate(model, train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation accuracy over 90%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make model from model state\n",
    "model.load_state_dict(torch.load('models/perm_20_model_state.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model,'models/model_permuted.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml4h",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
