{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This notebooks fits the cnn on permuted labeles for task 2.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import VGG16_Weights\n",
    "model = torchvision.models.vgg16(weights=VGG16_Weights.DEFAULT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_wo_norm = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "dataset0_wo_norm = torchvision.datasets.ImageFolder(\"archive/chest_xray/chest_xray/train\", transform=trans_wo_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: tensor([0.5832, 0.5832, 0.5832])\n",
      "Standard deviation: tensor([0.1413, 0.1413, 0.1413])\n"
     ]
    }
   ],
   "source": [
    "mean0 = torch.zeros(3)\n",
    "std0 = torch.zeros(3)\n",
    "for img, _ in dataset0_wo_norm:\n",
    "    mean0 += img.mean(dim=(1, 2))\n",
    "    std0 += img.std(dim=(1, 2))\n",
    "\n",
    "mean0 /= len(dataset0_wo_norm)\n",
    "std0 /= len(dataset0_wo_norm)\n",
    "\n",
    "print(\"Mean:\", mean0)\n",
    "print(\"Standard deviation:\", std0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean0 =torch.tensor([0.5832, 0.5832, 0.5832])\n",
    "std0  =torch.tensor([0.1413, 0.1413, 0.1413])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_normalise_0 = transforms.Normalize(\n",
    "    mean=mean0,\n",
    "    std=std0\n",
    ")\n",
    "\n",
    "trans0 = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.Grayscale(num_output_channels=3),\n",
    "        transforms.ToTensor(),\n",
    "        std_normalise_0\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_0 = torchvision.datasets.ImageFolder(\"archive/chest_xray/chest_xray/train\", transform=trans0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing computations on device = cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): ReLU(inplace=True)\n",
       "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): ReLU(inplace=True)\n",
       "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (27): ReLU(inplace=True)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "print('Doing computations on device = {}'.format(device))\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.classifier = nn.Sequential(\n",
    "    torch.nn.Linear(25088,4096),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Dropout(0.5, inplace = False),\n",
    "    torch.nn.Linear(4096,1000),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Dropout(0.5, inplace = False),\n",
    "    torch.nn.Linear(1000,2)\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we define train and validation set randomly as the validation set provided is too small for meaningful results\n",
    "trainset, testset = torch.utils.data.random_split(dataset_0, [4999, len(dataset_0) - 4999])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Permuted lables train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lables = np.array([lable for _, lable in trainset.dataset.imgs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "lables = np.random.permutation(lables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (_,lable) in enumerate(trainset.dataset.imgs):\n",
    "    trainset.dataset.imgs[i] = (trainset.dataset.imgs[i][0], lables[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(trainset,batch_size=32)\n",
    "test_loader  = torch.utils.data.DataLoader(testset,batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_long(net,train_loader,test_loader,epochs=5,lr=0.001,optimizer=None,loss_fn = nn.NLLLoss(),print_freq=10):\n",
    "    optimizer = optimizer or torch.optim.Adam(net.parameters(),lr=lr)\n",
    "    for epoch in range(epochs):\n",
    "        net.train()\n",
    "        total_loss,acc,count = 0,0,0\n",
    "        for i, (features,labels) in enumerate(train_loader):\n",
    "            lbls = labels.long().to(default_device)\n",
    "            optimizer.zero_grad()\n",
    "            out = net(features.to(default_device))\n",
    "            loss = loss_fn(out,lbls)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss+=loss\n",
    "            _,predicted = torch.max(out,1)\n",
    "            acc+=(predicted==lbls).sum()\n",
    "            count+=len(labels)\n",
    "            if i%print_freq==0:\n",
    "                print(\"Epoch {}, minibatch {}: train acc = {}, train loss = {}\".format(epoch,i,acc.item()/count,total_loss.item()/count))\n",
    "        vl,va = validate(net,test_loader,loss_fn)\n",
    "        print(\"Epoch {} done, validation acc = {}, validation loss = {}\".format(epoch,va,vl))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(net, dataloader,loss_fn=nn.NLLLoss()):\n",
    "    net.eval()\n",
    "    count,acc,loss = 0,0,0\n",
    "    with torch.no_grad():\n",
    "        for features,labels in dataloader:\n",
    "            \n",
    "            lbls = labels.long().to(default_device)\n",
    "            out = net(features.to(default_device))\n",
    "            loss += loss_fn(out,lbls) \n",
    "            pred = torch.max(out,1)[1]\n",
    "            acc += (pred==lbls).sum()\n",
    "            count += len(labels)\n",
    "    return loss.item()/count, acc.item()/count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.features.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, minibatch 0: train acc = 0.59375, train loss = 0.025424392893910408\n",
      "Epoch 0, minibatch 90: train acc = 0.7685439560439561, train loss = 0.015253140376164364\n",
      "Epoch 0 done, validation acc = 0.7465437788018433, validation loss = 0.02454330075171686\n",
      "Epoch 1, minibatch 0: train acc = 0.65625, train loss = 0.021235061809420586\n",
      "Epoch 1, minibatch 90: train acc = 0.8097527472527473, train loss = 0.013097489273155129\n",
      "Epoch 1 done, validation acc = 0.7327188940092166, validation loss = 0.02657625532370009\n",
      "Epoch 2, minibatch 0: train acc = 0.78125, train loss = 0.015305490233004093\n",
      "Epoch 2, minibatch 90: train acc = 0.8557692307692307, train loss = 0.010443801408285623\n",
      "Epoch 2 done, validation acc = 0.6912442396313364, validation loss = 0.02891362537436771\n",
      "Epoch 3, minibatch 0: train acc = 0.875, train loss = 0.011072671040892601\n",
      "Epoch 3, minibatch 90: train acc = 0.8835851648351648, train loss = 0.008529849104828888\n",
      "Epoch 3 done, validation acc = 0.7096774193548387, validation loss = 0.034194018983621205\n",
      "Epoch 4, minibatch 0: train acc = 0.9375, train loss = 0.00791700929403305\n",
      "Epoch 4, minibatch 90: train acc = 0.9196428571428571, train loss = 0.006510454219776195\n",
      "Epoch 4 done, validation acc = 0.728110599078341, validation loss = 0.030665175706010808\n",
      "Epoch 5, minibatch 0: train acc = 0.90625, train loss = 0.0064531671814620495\n",
      "Epoch 5, minibatch 90: train acc = 0.9481456043956044, train loss = 0.004693272022100596\n",
      "Epoch 5 done, validation acc = 0.7235023041474654, validation loss = 0.030640059352470432\n",
      "Epoch 6, minibatch 0: train acc = 0.875, train loss = 0.007190646603703499\n",
      "Epoch 6, minibatch 90: train acc = 0.961195054945055, train loss = 0.0039198745738019\n",
      "Epoch 6 done, validation acc = 0.7419354838709677, validation loss = 0.033106195212509223\n",
      "Epoch 7, minibatch 0: train acc = 0.84375, train loss = 0.008086223155260086\n",
      "Epoch 7, minibatch 90: train acc = 0.9694368131868132, train loss = 0.003321812375561222\n",
      "Epoch 7 done, validation acc = 0.6036866359447005, validation loss = 0.025030764566588513\n",
      "Epoch 8, minibatch 0: train acc = 0.96875, train loss = 0.007798501756042242\n",
      "Epoch 8, minibatch 90: train acc = 0.9649725274725275, train loss = 0.0039737028080028495\n",
      "Epoch 8 done, validation acc = 0.6036866359447005, validation loss = 0.02783070621402582\n",
      "Epoch 9, minibatch 0: train acc = 0.90625, train loss = 0.006282333750277758\n",
      "Epoch 9, minibatch 90: train acc = 0.9766483516483516, train loss = 0.0029057595101031628\n",
      "Epoch 9 done, validation acc = 0.6082949308755761, validation loss = 0.03241279487785656\n"
     ]
    }
   ],
   "source": [
    "default_device = device\n",
    "train_long(model,train_loader,test_loader,lr=0.00005,loss_fn=torch.nn.CrossEntropyLoss(),epochs=10,print_freq=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.05818962864838593, 0.9797959591918384)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate(model, train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation accuracy over 95%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model,'models/model_permuted.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml4h",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
