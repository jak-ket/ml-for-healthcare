{
  "cells": [
    {
      "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
      "execution_count": 4,
      "metadata": {
        "id": "2sJWPWow9SXF"
      },
      "outputs": [],
      "source": [
=======
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
=======
      "execution_count": 4,
>>>>>>> 3fd1e04 (clean files)
      "metadata": {
        "id": "2sJWPWow9SXF"
      },
      "outputs": [],
      "source": [
        "import multiprocessing\n",
>>>>>>> 88c8b7e (fine tuning strategies)
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch import optim\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import accuracy_score, f1_score, balanced_accuracy_score\n",
        "from lightgbm import LGBMClassifier\n",
<<<<<<< HEAD
        "from torch.utils.data import DataLoader, TensorDataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "HJT0iuIW-9Ua"
      },
      "outputs": [],
      "source": [
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
=======
        "from tqdm import tqdm\n",
        "from torch.utils.data import Dataset, DataLoader, TensorDataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "HJT0iuIW-9Ua"
      },
<<<<<<< HEAD
      "execution_count": 5,
      "outputs": []
>>>>>>> 88c8b7e (fine tuning strategies)
=======
      "outputs": [],
      "source": [
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
>>>>>>> 3fd1e04 (clean files)
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IxGUtYNR8MDr"
      },
      "source": [
        "# Q4: Finetuning Strategies using Encoder from Q1"
      ]
    },
    {
      "cell_type": "markdown",
<<<<<<< HEAD
<<<<<<< HEAD
      "metadata": {
        "id": "GSpJYKw2IoOG"
      },
      "source": [
        "Load pretrained cnn classifier and create encoder by removing classification head"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
=======
      "source": [
        "Load pretrained cnn classifier and create encoder by removing classification head"
      ],
=======
>>>>>>> 3fd1e04 (clean files)
      "metadata": {
        "id": "GSpJYKw2IoOG"
      },
      "source": [
        "Load pretrained cnn classifier and create encoder by removing classification head"
      ]
    },
    {
      "cell_type": "code",
<<<<<<< HEAD
      "source": [
        "cnn_clf = torch.load(\"transfercnn.pth\")\n",
        "cnn_clf"
      ],
>>>>>>> 88c8b7e (fine tuning strategies)
=======
      "execution_count": 6,
>>>>>>> 3fd1e04 (clean files)
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zAB69uHDIe6Y",
        "outputId": "e167aa3b-fa4b-485c-ae7b-6804c263a884"
      },
<<<<<<< HEAD
<<<<<<< HEAD
      "outputs": [
        {
=======
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
>>>>>>> 88c8b7e (fine tuning strategies)
=======
      "outputs": [
        {
>>>>>>> 3fd1e04 (clean files)
          "data": {
            "text/plain": [
              "cnn(\n",
              "  (conv1): Conv1d(1, 64, kernel_size=(3,), stride=(1,))\n",
              "  (conv2): Conv1d(64, 128, kernel_size=(3,), stride=(1,))\n",
              "  (conv3): Conv1d(128, 256, kernel_size=(3,), stride=(1,))\n",
              "  (fc1): Linear(in_features=5376, out_features=128, bias=True)\n",
              "  (fc2): Linear(in_features=128, out_features=5, bias=True)\n",
              "  (relu): ReLU()\n",
              "  (pool): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              ")"
            ]
          },
<<<<<<< HEAD
<<<<<<< HEAD
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cnn_clf = torch.load(\"transfercnn.pth\")\n",
        "cnn_clf"
=======
=======
          "execution_count": 6,
>>>>>>> 3fd1e04 (clean files)
          "metadata": {},
          "output_type": "execute_result"
        }
<<<<<<< HEAD
>>>>>>> 88c8b7e (fine tuning strategies)
=======
      ],
      "source": [
        "cnn_clf = torch.load(\"transfercnn.pth\")\n",
        "cnn_clf"
>>>>>>> 3fd1e04 (clean files)
      ]
    },
    {
      "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
=======
>>>>>>> 3fd1e04 (clean files)
      "execution_count": 7,
      "metadata": {
        "id": "adIIYV4rTvFJ"
      },
      "outputs": [],
<<<<<<< HEAD
=======
>>>>>>> 88c8b7e (fine tuning strategies)
=======
>>>>>>> 3fd1e04 (clean files)
      "source": [
        "def get_encoder():\n",
        "  \"\"\"\n",
        "  create encoder by omitting classification head\n",
        "  architecture is identical to autoencoder, but training task is different: classification instead of unsupervised reconstruction\n",
        "  \"\"\"\n",
        "  cnn_clf = torch.load(\"transfercnn.pth\")\n",
        "  encoder = torch.nn.Sequential(\n",
        "    cnn_clf.conv1,\n",
        "    torch.nn.ReLU(),\n",
        "    cnn_clf.pool,\n",
        "    cnn_clf.conv2,\n",
        "    torch.nn.ReLU(),\n",
        "    cnn_clf.pool,\n",
        "    cnn_clf.conv3,\n",
        "    torch.nn.ReLU(),\n",
        "    cnn_clf.pool,\n",
        "    torch.nn.Flatten(1),\n",
        "    cnn_clf.fc1\n",
        "  )\n",
        "  encoder = encoder.to(DEVICE)\n",
        "  return encoder\n",
        "\n",
        "encoder = get_encoder()"
<<<<<<< HEAD
<<<<<<< HEAD
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
=======
      ],
      "metadata": {
        "id": "adIIYV4rTvFJ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(encoder)"
      ],
>>>>>>> 88c8b7e (fine tuning strategies)
=======
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
>>>>>>> 3fd1e04 (clean files)
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LeqYbMts1S0R",
        "outputId": "6322af68-0510-4250-c528-228ee5a30f4e"
      },
<<<<<<< HEAD
<<<<<<< HEAD
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
=======
      "execution_count": 28,
=======
>>>>>>> 3fd1e04 (clean files)
      "outputs": [
        {
          "name": "stdout",
<<<<<<< HEAD
>>>>>>> 88c8b7e (fine tuning strategies)
=======
          "output_type": "stream",
>>>>>>> 3fd1e04 (clean files)
          "text": [
            "Sequential(\n",
            "  (0): Conv1d(1, 64, kernel_size=(3,), stride=(1,))\n",
            "  (1): ReLU()\n",
            "  (2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (3): Conv1d(64, 128, kernel_size=(3,), stride=(1,))\n",
            "  (4): ReLU()\n",
            "  (5): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (6): Conv1d(128, 256, kernel_size=(3,), stride=(1,))\n",
            "  (7): ReLU()\n",
            "  (8): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (9): Flatten(start_dim=1, end_dim=-1)\n",
            "  (10): Linear(in_features=5376, out_features=128, bias=True)\n",
            ")\n"
          ]
        }
<<<<<<< HEAD
<<<<<<< HEAD
      ],
      "source": [
        "print(encoder)"
=======
>>>>>>> 88c8b7e (fine tuning strategies)
=======
      ],
      "source": [
        "print(encoder)"
>>>>>>> 3fd1e04 (clean files)
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s7m76Gt58MDu"
      },
      "source": [
        "## 1. Classic ML\n",
        "Similar to Q3,\n",
        "- obtain representations for the PTB dataset by feeding the dataset through the pre-trained encoder\n",
        "- Use a classic ML method from Part 1 to train and test for the PTB task using these representations"
      ]
    },
    {
      "cell_type": "markdown",
<<<<<<< HEAD
<<<<<<< HEAD
      "metadata": {
        "id": "0vvr57tk9pWi"
      },
      "source": [
        "### Encode dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Q9oCJsU797yf"
      },
      "outputs": [],
=======
      "source": [
        "### Encode dataset"
      ],
=======
>>>>>>> 3fd1e04 (clean files)
      "metadata": {
        "id": "0vvr57tk9pWi"
      },
      "source": [
        "### Encode dataset"
      ]
    },
    {
      "cell_type": "code",
<<<<<<< HEAD
>>>>>>> 88c8b7e (fine tuning strategies)
=======
      "execution_count": 8,
      "metadata": {
        "id": "Q9oCJsU797yf"
      },
      "outputs": [],
>>>>>>> 3fd1e04 (clean files)
      "source": [
        "# load data\n",
        "train = pd.read_csv(\"ptbdb_train.csv\", header=None)\n",
        "test = pd.read_csv(\"ptbdb_test.csv\", header=None)\n",
        "\n",
        "X_train = train.drop(187, axis=1)\n",
        "X_test = test.drop(187, axis=1)\n",
        "\n",
        "y_train = train[187]\n",
        "y_test = test[187]"
<<<<<<< HEAD
<<<<<<< HEAD
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "VccPXDJ595iP"
      },
      "outputs": [],
=======
      ],
      "metadata": {
        "id": "Q9oCJsU797yf"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
>>>>>>> 88c8b7e (fine tuning strategies)
=======
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "VccPXDJ595iP"
      },
      "outputs": [],
>>>>>>> 3fd1e04 (clean files)
      "source": [
        "# feed data through encoder model to get embeddings\n",
        "\n",
        "def get_encodings(model, X, device, batchsize=64):\n",
        "  X_tensor = torch.tensor(X.values, dtype=torch.float32)\n",
        "  X_dataloader = DataLoader(X_tensor, batch_size=batchsize, shuffle=False)\n",
        "\n",
        "  encodings = []\n",
        "\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    for x_batch in X_dataloader:\n",
        "      x_batch = x_batch.unsqueeze(1)\n",
        "      x_batch = x_batch.to(device)\n",
        "      x_batch_encoding = model(x_batch)\n",
        "      encodings.append(x_batch_encoding.detach().cpu().numpy())\n",
        "\n",
        "  return encodings\n",
        "\n",
        "X_train_encodings = get_encodings(model=encoder, X=X_train, device=DEVICE)\n",
        "X_test_encodings = get_encodings(model=encoder, X=X_test, device=DEVICE)"
<<<<<<< HEAD
<<<<<<< HEAD
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "unFlPfY2DGu8"
      },
      "outputs": [],
=======
      ],
      "metadata": {
        "id": "VccPXDJ595iP"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
>>>>>>> 88c8b7e (fine tuning strategies)
=======
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "unFlPfY2DGu8"
      },
      "outputs": [],
>>>>>>> 3fd1e04 (clean files)
      "source": [
        "# create numpy matrices from list of batches\n",
        "X_train_encodings = np.vstack(X_train_encodings)\n",
        "X_test_encodings = np.vstack(X_test_encodings)"
<<<<<<< HEAD
<<<<<<< HEAD
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
=======
      ],
      "metadata": {
        "id": "unFlPfY2DGu8"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_encodings.shape"
      ],
>>>>>>> 88c8b7e (fine tuning strategies)
=======
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
>>>>>>> 3fd1e04 (clean files)
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AZWLZBhLGWCl",
        "outputId": "71bf0cc3-adaa-4b81-f883-58f9b34a1d20"
      },
<<<<<<< HEAD
<<<<<<< HEAD
      "outputs": [
        {
=======
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
>>>>>>> 88c8b7e (fine tuning strategies)
=======
      "outputs": [
        {
>>>>>>> 3fd1e04 (clean files)
          "data": {
            "text/plain": [
              "(11641, 128)"
            ]
          },
<<<<<<< HEAD
<<<<<<< HEAD
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train_encodings.shape"
=======
=======
          "execution_count": 11,
>>>>>>> 3fd1e04 (clean files)
          "metadata": {},
          "output_type": "execute_result"
        }
<<<<<<< HEAD
>>>>>>> 88c8b7e (fine tuning strategies)
=======
      ],
      "source": [
        "X_train_encodings.shape"
>>>>>>> 3fd1e04 (clean files)
      ]
    },
    {
      "cell_type": "markdown",
<<<<<<< HEAD
<<<<<<< HEAD
      "metadata": {
        "id": "b3zOLOP19zVh"
      },
      "source": [
        "### Train and Test classic ML model"
      ]
=======
      "source": [
        "### Train and Test classic ML model"
      ],
      "metadata": {
        "id": "b3zOLOP19zVh"
      }
>>>>>>> 88c8b7e (fine tuning strategies)
=======
      "metadata": {
        "id": "b3zOLOP19zVh"
      },
      "source": [
        "### Train and Test classic ML model"
      ]
>>>>>>> 3fd1e04 (clean files)
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
<<<<<<< HEAD
<<<<<<< HEAD
=======
        "vscode": {
          "languageId": "plaintext"
        },
>>>>>>> 88c8b7e (fine tuning strategies)
=======
>>>>>>> 3fd1e04 (clean files)
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "collapsed": true,
        "id": "m4IFsOje8MDu",
<<<<<<< HEAD
<<<<<<< HEAD
=======
>>>>>>> 3fd1e04 (clean files)
        "outputId": "5ae242dc-05e0-4374-b97f-fcf6e3f97701",
        "vscode": {
          "languageId": "plaintext"
        }
<<<<<<< HEAD
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMClassifier(max_depth=9, n_estimators=500, verbose=-1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(max_depth=9, n_estimators=500, verbose=-1)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "LGBMClassifier(max_depth=9, n_estimators=500, verbose=-1)"
            ]
          },
          "execution_count": 68,
          "metadata": {},
          "output_type": "execute_result"
=======
        "outputId": "5ae242dc-05e0-4374-b97f-fcf6e3f97701"
=======
>>>>>>> 3fd1e04 (clean files)
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMClassifier(max_depth=9, n_estimators=500, verbose=-1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(max_depth=9, n_estimators=500, verbose=-1)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "LGBMClassifier(max_depth=9, n_estimators=500, verbose=-1)"
            ]
          },
          "execution_count": 68,
          "metadata": {},
<<<<<<< HEAD
          "execution_count": 68
>>>>>>> 88c8b7e (fine tuning strategies)
=======
          "output_type": "execute_result"
>>>>>>> 3fd1e04 (clean files)
        }
      ],
      "source": [
        "# train classic ML model\n",
        "clf = LGBMClassifier(verbose=-1, n_estimators=500, learning_rate=0.1, max_depth=9) # choose parameters from part 1\n",
        "clf.fit(X_train_encodings, y_train)"
      ]
    },
    {
      "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xOvbYuSzbsvz",
        "outputId": "99e03a30-5095-4743-e524-48b7c73b4e3d"
      },
      "outputs": [
        {
=======
      "source": [
        "# test performance\n",
        "y_pred = clf.predict(X_test_encodings)\n",
        "accuracy_score(y_pred, y_test), f1_score(y_pred, y_test), balanced_accuracy_score(y_pred, y_test)"
      ],
=======
      "execution_count": 69,
>>>>>>> 3fd1e04 (clean files)
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xOvbYuSzbsvz",
        "outputId": "99e03a30-5095-4743-e524-48b7c73b4e3d"
      },
      "outputs": [
        {
<<<<<<< HEAD
          "output_type": "execute_result",
>>>>>>> 88c8b7e (fine tuning strategies)
=======
>>>>>>> 3fd1e04 (clean files)
          "data": {
            "text/plain": [
              "(0.9615252490553075, 0.9734345351043644, 0.9539682275895061)"
            ]
          },
<<<<<<< HEAD
<<<<<<< HEAD
          "execution_count": 69,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# test performance\n",
        "y_pred = clf.predict(X_test_encodings)\n",
        "accuracy_score(y_pred, y_test), f1_score(y_pred, y_test), balanced_accuracy_score(y_pred, y_test)"
=======
=======
          "execution_count": 69,
>>>>>>> 3fd1e04 (clean files)
          "metadata": {},
          "output_type": "execute_result"
        }
<<<<<<< HEAD
>>>>>>> 88c8b7e (fine tuning strategies)
=======
      ],
      "source": [
        "# test performance\n",
        "y_pred = clf.predict(X_test_encodings)\n",
        "accuracy_score(y_pred, y_test), f1_score(y_pred, y_test), balanced_accuracy_score(y_pred, y_test)"
>>>>>>> 3fd1e04 (clean files)
      ]
    },
    {
      "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "id": "YAdhKQqOXpwz",
        "outputId": "f17af8b6-ae84-4b91-d7ed-576aba923a52"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=LGBMClassifier(verbose=-1), n_jobs=-1,\n",
              "             param_grid={&#x27;learning_rate&#x27;: [0.01, 0.1, 1],\n",
              "                         &#x27;max_depth&#x27;: [3, 5, 7, 9],\n",
              "                         &#x27;n_estimators&#x27;: [100, 200, 300, 400, 500]},\n",
              "             scoring=&#x27;f1&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=LGBMClassifier(verbose=-1), n_jobs=-1,\n",
              "             param_grid={&#x27;learning_rate&#x27;: [0.01, 0.1, 1],\n",
              "                         &#x27;max_depth&#x27;: [3, 5, 7, 9],\n",
              "                         &#x27;n_estimators&#x27;: [100, 200, 300, 400, 500]},\n",
              "             scoring=&#x27;f1&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(verbose=-1)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(verbose=-1)</pre></div></div></div></div></div></div></div></div></div></div>"
            ],
            "text/plain": [
              "GridSearchCV(cv=5, estimator=LGBMClassifier(verbose=-1), n_jobs=-1,\n",
              "             param_grid={'learning_rate': [0.01, 0.1, 1],\n",
              "                         'max_depth': [3, 5, 7, 9],\n",
              "                         'n_estimators': [100, 200, 300, 400, 500]},\n",
              "             scoring='f1')"
            ]
          },
          "execution_count": 70,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
=======
>>>>>>> 88c8b7e (fine tuning strategies)
      "source": [
        "# train classic ML model\n",
        "param_grid = {'n_estimators': [100, 200, 300, 400, 500],\n",
        "              'learning_rate': [0.01, 0.1, 1],\n",
        "              'max_depth': [3, 5, 7, 9]}\n",
        "\n",
        "clf = LGBMClassifier(verbose=-1)\n",
        "\n",
        "grid_search = GridSearchCV(clf, param_grid, cv=5, scoring='f1', n_jobs=-1)\n",
        "grid_search.fit(X_train_encodings, y_train)"
<<<<<<< HEAD
=======
      ],
=======
      "execution_count": 70,
>>>>>>> 3fd1e04 (clean files)
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "id": "YAdhKQqOXpwz",
        "outputId": "f17af8b6-ae84-4b91-d7ed-576aba923a52"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=LGBMClassifier(verbose=-1), n_jobs=-1,\n",
              "             param_grid={&#x27;learning_rate&#x27;: [0.01, 0.1, 1],\n",
              "                         &#x27;max_depth&#x27;: [3, 5, 7, 9],\n",
              "                         &#x27;n_estimators&#x27;: [100, 200, 300, 400, 500]},\n",
              "             scoring=&#x27;f1&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=LGBMClassifier(verbose=-1), n_jobs=-1,\n",
              "             param_grid={&#x27;learning_rate&#x27;: [0.01, 0.1, 1],\n",
              "                         &#x27;max_depth&#x27;: [3, 5, 7, 9],\n",
              "                         &#x27;n_estimators&#x27;: [100, 200, 300, 400, 500]},\n",
              "             scoring=&#x27;f1&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(verbose=-1)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(verbose=-1)</pre></div></div></div></div></div></div></div></div></div></div>"
            ],
            "text/plain": [
              "GridSearchCV(cv=5, estimator=LGBMClassifier(verbose=-1), n_jobs=-1,\n",
              "             param_grid={'learning_rate': [0.01, 0.1, 1],\n",
              "                         'max_depth': [3, 5, 7, 9],\n",
              "                         'n_estimators': [100, 200, 300, 400, 500]},\n",
              "             scoring='f1')"
            ]
          },
          "execution_count": 70,
          "metadata": {},
          "output_type": "execute_result"
        }
<<<<<<< HEAD
>>>>>>> 88c8b7e (fine tuning strategies)
=======
      ],
      "source": [
        "# train classic ML model\n",
        "param_grid = {'n_estimators': [100, 200, 300, 400, 500],\n",
        "              'learning_rate': [0.01, 0.1, 1],\n",
        "              'max_depth': [3, 5, 7, 9]}\n",
        "\n",
        "clf = LGBMClassifier(verbose=-1)\n",
        "\n",
        "grid_search = GridSearchCV(clf, param_grid, cv=5, scoring='f1', n_jobs=-1)\n",
        "grid_search.fit(X_train_encodings, y_train)"
>>>>>>> 3fd1e04 (clean files)
      ]
    },
    {
      "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
      "execution_count": 72,
=======
      "source": [
        "print(\"Best parameters: {}\".format(grid_search.best_params_))"
      ],
>>>>>>> 88c8b7e (fine tuning strategies)
=======
      "execution_count": 72,
>>>>>>> 3fd1e04 (clean files)
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g2QB1JoReIq9",
        "outputId": "24a41c1a-c4dd-4e34-9745-4c1cc2863d61"
      },
<<<<<<< HEAD
<<<<<<< HEAD
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
=======
      "execution_count": 72,
=======
>>>>>>> 3fd1e04 (clean files)
      "outputs": [
        {
          "name": "stdout",
<<<<<<< HEAD
>>>>>>> 88c8b7e (fine tuning strategies)
=======
          "output_type": "stream",
>>>>>>> 3fd1e04 (clean files)
          "text": [
            "Best parameters: {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 500}\n"
          ]
        }
<<<<<<< HEAD
<<<<<<< HEAD
      ],
      "source": [
        "print(\"Best parameters: {}\".format(grid_search.best_params_))"
=======
>>>>>>> 88c8b7e (fine tuning strategies)
=======
      ],
      "source": [
        "print(\"Best parameters: {}\".format(grid_search.best_params_))"
>>>>>>> 3fd1e04 (clean files)
      ]
    },
    {
      "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
      "execution_count": 73,
=======
      "source": [
        "# test performance\n",
        "y_pred = grid_search.predict(X_test_encodings)\n",
        "accuracy_score(y_pred, y_test), f1_score(y_pred, y_test), balanced_accuracy_score(y_pred, y_test)"
      ],
>>>>>>> 88c8b7e (fine tuning strategies)
=======
      "execution_count": 73,
>>>>>>> 3fd1e04 (clean files)
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bzigwYgCTJAR",
        "outputId": "1fb32da4-1563-42c7-944b-9a53496bf267"
      },
<<<<<<< HEAD
<<<<<<< HEAD
      "outputs": [
        {
=======
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
>>>>>>> 88c8b7e (fine tuning strategies)
=======
      "outputs": [
        {
>>>>>>> 3fd1e04 (clean files)
          "data": {
            "text/plain": [
              "(0.9615252490553075, 0.9733713742272944, 0.952377544866449)"
            ]
          },
<<<<<<< HEAD
<<<<<<< HEAD
          "execution_count": 73,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# test performance\n",
        "y_pred = grid_search.predict(X_test_encodings)\n",
        "accuracy_score(y_pred, y_test), f1_score(y_pred, y_test), balanced_accuracy_score(y_pred, y_test)"
=======
=======
          "execution_count": 73,
>>>>>>> 3fd1e04 (clean files)
          "metadata": {},
          "output_type": "execute_result"
        }
<<<<<<< HEAD
>>>>>>> 88c8b7e (fine tuning strategies)
=======
      ],
      "source": [
        "# test performance\n",
        "y_pred = grid_search.predict(X_test_encodings)\n",
        "accuracy_score(y_pred, y_test), f1_score(y_pred, y_test), balanced_accuracy_score(y_pred, y_test)"
>>>>>>> 3fd1e04 (clean files)
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0KCyZnYX8MDw"
      },
      "source": [
        "## 2. ANNs\n",
        "Add output layer(s) for the PTB binary class to your encoder model. Implement the following finetuning strategies\n",
        "- Train the output layer(s) only on the PTB dataset, freezing the encoder\n",
        "- Train the entire model on the PTB dataset (encoder + output layers).\n",
        "- First, train the output layers, then unfreeze and train the entire joint model in two\n",
        "separate stages."
      ]
    },
    {
      "cell_type": "markdown",
<<<<<<< HEAD
<<<<<<< HEAD
      "metadata": {
        "id": "ZZKUMssfG8pA"
      },
      "source": [
        "### Add output layer(s) for the PTB binary class to your encoder model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "94mCzbnAG7pk"
      },
      "outputs": [],
=======
      "source": [
        "### Add output layer(s) for the PTB binary class to your encoder model."
      ],
=======
>>>>>>> 3fd1e04 (clean files)
      "metadata": {
        "id": "ZZKUMssfG8pA"
      },
      "source": [
        "### Add output layer(s) for the PTB binary class to your encoder model."
      ]
    },
    {
      "cell_type": "code",
<<<<<<< HEAD
>>>>>>> 88c8b7e (fine tuning strategies)
=======
      "execution_count": 12,
      "metadata": {
        "id": "94mCzbnAG7pk"
      },
      "outputs": [],
>>>>>>> 3fd1e04 (clean files)
      "source": [
        "class TimeSeriesClassifier(torch.nn.Module):\n",
        "  def __init__(self, encoder, hidden_size, layer_sizes, dropout_prob):\n",
        "    super(TimeSeriesClassifier, self).__init__()\n",
        "    self.encoder = encoder\n",
        "    self.classifier = torch.nn.Sequential(\n",
        "        torch.nn.Linear(hidden_size, layer_sizes[0]),\n",
        "        torch.nn.ReLU(),\n",
        "        torch.nn.Dropout(dropout_prob),\n",
        "        torch.nn.Linear(layer_sizes[0], layer_sizes[1]),\n",
        "        torch.nn.ReLU(),\n",
        "        torch.nn.Dropout(dropout_prob),\n",
        "        torch.nn.Linear(layer_sizes[1], 1),\n",
        "        torch.nn.Sigmoid()\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.classifier(self.encoder(x))"
<<<<<<< HEAD
<<<<<<< HEAD
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "L1kaYlTPLFo5"
      },
      "outputs": [],
=======
      ],
      "metadata": {
        "id": "94mCzbnAG7pk"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
>>>>>>> 88c8b7e (fine tuning strategies)
=======
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "L1kaYlTPLFo5"
      },
      "outputs": [],
>>>>>>> 3fd1e04 (clean files)
      "source": [
        "def train_clf(model, epochs, batch_size, train_loader, lr, device):\n",
        "  criterion = torch.nn.BCELoss()\n",
        "  optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "\n",
        "      model.train()\n",
        "\n",
        "      epoch_loss = 0\n",
        "\n",
        "      for X, y in train_loader:\n",
        "\n",
        "          X = X.to(DEVICE)\n",
        "          y = y.to(DEVICE)\n",
        "\n",
        "          y_pred = model(X.unsqueeze(1))\n",
        "\n",
        "          # loss = criterion(y_pred, batch[\"score\"])\n",
        "          loss = criterion(y_pred.squeeze(1), y)\n",
        "\n",
        "          # backward pass\n",
        "          optimizer.zero_grad()\n",
        "          loss.backward()\n",
        "\n",
        "          # update weights\n",
        "          optimizer.step()\n",
        "\n",
        "          epoch_loss += loss.item()\n",
        "\n",
        "      print(f\"epoch {epoch} train loss {epoch_loss}\")"
<<<<<<< HEAD
<<<<<<< HEAD
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "t__9qS3cQn7q"
      },
      "outputs": [],
=======
      ],
      "metadata": {
        "id": "L1kaYlTPLFo5"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
>>>>>>> 88c8b7e (fine tuning strategies)
=======
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "t__9qS3cQn7q"
      },
      "outputs": [],
>>>>>>> 3fd1e04 (clean files)
      "source": [
        "def get_predictions(model, test_loader):\n",
        "  y_preds = []\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    for X, y in test_loader:\n",
        "      X = X.to(DEVICE)\n",
        "      y = y.to(DEVICE)\n",
        "      y_pred = model(X.unsqueeze(1))\n",
        "      y_preds.append(y_pred.detach().cpu().numpy())\n",
        "  return np.round(np.vstack(y_preds))"
<<<<<<< HEAD
<<<<<<< HEAD
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "oPnTZhF7NZAP"
      },
      "outputs": [],
=======
      ],
      "metadata": {
        "id": "t__9qS3cQn7q"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
>>>>>>> 88c8b7e (fine tuning strategies)
=======
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "oPnTZhF7NZAP"
      },
      "outputs": [],
>>>>>>> 3fd1e04 (clean files)
      "source": [
        "train_dataset = TensorDataset(torch.tensor(X_train.to_numpy(), dtype=torch.float32), torch.tensor(y_train, dtype=torch.float32))\n",
        "test_dataset = TensorDataset(torch.tensor(X_test.to_numpy(), dtype=torch.float32), torch.tensor(y_test, dtype=torch.float32))\n",
        "\n",
        "BATCH_SIZE = 64\n",
        "train_loader = DataLoader(train_dataset, shuffle=False, batch_size=BATCH_SIZE, pin_memory=True)\n",
        "test_loader = DataLoader(test_dataset, shuffle=False, batch_size=BATCH_SIZE, pin_memory=True)"
<<<<<<< HEAD
<<<<<<< HEAD
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "_V3dR33vPWJ0"
      },
      "outputs": [],
=======
      ],
      "metadata": {
        "id": "oPnTZhF7NZAP"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
>>>>>>> 88c8b7e (fine tuning strategies)
=======
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "_V3dR33vPWJ0"
      },
      "outputs": [],
>>>>>>> 3fd1e04 (clean files)
      "source": [
        "N_EPOCHS = 15\n",
        "LR = 0.0003\n",
        "hidden_size = 128 # bottleneck dimension of encoder"
<<<<<<< HEAD
<<<<<<< HEAD
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZvhU1RYGuR9"
      },
      "source": [
        "### 1 Train the output layer(s) only on the PTB dataset, freezing the encoder"
      ]
=======
      ],
      "metadata": {
        "id": "_V3dR33vPWJ0"
      },
      "execution_count": 17,
      "outputs": []
=======
      ]
>>>>>>> 3fd1e04 (clean files)
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZvhU1RYGuR9"
<<<<<<< HEAD
      }
>>>>>>> 88c8b7e (fine tuning strategies)
=======
      },
      "source": [
        "### 1 Train the output layer(s) only on the PTB dataset, freezing the encoder"
      ]
>>>>>>> 3fd1e04 (clean files)
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
<<<<<<< HEAD
<<<<<<< HEAD
        "id": "3i5Ki0Fw8MDx",
        "vscode": {
          "languageId": "plaintext"
        }
=======
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "3i5Ki0Fw8MDx"
>>>>>>> 88c8b7e (fine tuning strategies)
=======
        "id": "3i5Ki0Fw8MDx",
        "vscode": {
          "languageId": "plaintext"
        }
>>>>>>> 3fd1e04 (clean files)
      },
      "outputs": [],
      "source": [
        "encoder = get_encoder()\n",
        "model1 = TimeSeriesClassifier(encoder=encoder, hidden_size=hidden_size, layer_sizes=[hidden_size, int(hidden_size/2)], dropout_prob=0.05)\n",
        "model1 = model1.to(DEVICE)\n",
        "\n",
        "# freeze encoder\n",
        "for param in model1.encoder.parameters():\n",
        "    param.requires_grad = False"
      ]
    },
    {
      "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
      "execution_count": 30,
=======
      "source": [
        "model1"
      ],
>>>>>>> 88c8b7e (fine tuning strategies)
=======
      "execution_count": 30,
>>>>>>> 3fd1e04 (clean files)
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VL_CQGfJ2sQa",
        "outputId": "505e67cb-8f03-4502-98d5-f640b2ab901f"
      },
<<<<<<< HEAD
<<<<<<< HEAD
      "outputs": [
        {
=======
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
>>>>>>> 88c8b7e (fine tuning strategies)
=======
      "outputs": [
        {
>>>>>>> 3fd1e04 (clean files)
          "data": {
            "text/plain": [
              "TimeSeriesClassifier(\n",
              "  (encoder): Sequential(\n",
              "    (0): Conv1d(1, 64, kernel_size=(3,), stride=(1,))\n",
              "    (1): ReLU()\n",
              "    (2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (3): Conv1d(64, 128, kernel_size=(3,), stride=(1,))\n",
              "    (4): ReLU()\n",
              "    (5): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (6): Conv1d(128, 256, kernel_size=(3,), stride=(1,))\n",
              "    (7): ReLU()\n",
              "    (8): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (9): Flatten(start_dim=1, end_dim=-1)\n",
              "    (10): Linear(in_features=5376, out_features=128, bias=True)\n",
              "  )\n",
              "  (classifier): Sequential(\n",
              "    (0): Linear(in_features=128, out_features=128, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Dropout(p=0.05, inplace=False)\n",
              "    (3): Linear(in_features=128, out_features=64, bias=True)\n",
              "    (4): ReLU()\n",
              "    (5): Dropout(p=0.05, inplace=False)\n",
              "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
              "    (7): Sigmoid()\n",
              "  )\n",
              ")"
            ]
          },
<<<<<<< HEAD
<<<<<<< HEAD
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model1"
=======
=======
          "execution_count": 30,
>>>>>>> 3fd1e04 (clean files)
          "metadata": {},
          "output_type": "execute_result"
        }
<<<<<<< HEAD
>>>>>>> 88c8b7e (fine tuning strategies)
=======
      ],
      "source": [
        "model1"
>>>>>>> 3fd1e04 (clean files)
      ]
    },
    {
      "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
      "execution_count": 19,
=======
      "source": [
        "train_clf(model=model1, epochs=N_EPOCHS, batch_size=BATCH_SIZE, train_loader=train_loader, lr=LR, device=DEVICE)"
      ],
>>>>>>> 88c8b7e (fine tuning strategies)
=======
      "execution_count": 19,
>>>>>>> 3fd1e04 (clean files)
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0KhaLEPMK-xy",
        "outputId": "f1ebf7dc-a7bb-4be3-f874-7cf908d7d411"
      },
<<<<<<< HEAD
<<<<<<< HEAD
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
=======
      "execution_count": 19,
=======
>>>>>>> 3fd1e04 (clean files)
      "outputs": [
        {
          "name": "stdout",
<<<<<<< HEAD
>>>>>>> 88c8b7e (fine tuning strategies)
=======
          "output_type": "stream",
>>>>>>> 3fd1e04 (clean files)
          "text": [
            "epoch 0 train loss 62.9109970331192\n",
            "epoch 1 train loss 41.20921067148447\n",
            "epoch 2 train loss 31.97341202944517\n",
            "epoch 3 train loss 26.79531602561474\n",
            "epoch 4 train loss 22.565235674381256\n",
            "epoch 5 train loss 19.750992834568024\n",
            "epoch 6 train loss 17.604126166552305\n",
            "epoch 7 train loss 15.717937434092164\n",
            "epoch 8 train loss 14.236774390563369\n",
            "epoch 9 train loss 13.41732779238373\n",
            "epoch 10 train loss 12.368765527382493\n",
            "epoch 11 train loss 11.40133083704859\n",
            "epoch 12 train loss 9.893328723497689\n",
            "epoch 13 train loss 9.949879417195916\n",
            "epoch 14 train loss 8.683293241541833\n"
          ]
        }
<<<<<<< HEAD
<<<<<<< HEAD
      ],
      "source": [
        "train_clf(model=model1, epochs=N_EPOCHS, batch_size=BATCH_SIZE, train_loader=train_loader, lr=LR, device=DEVICE)"
=======
>>>>>>> 88c8b7e (fine tuning strategies)
=======
      ],
      "source": [
        "train_clf(model=model1, epochs=N_EPOCHS, batch_size=BATCH_SIZE, train_loader=train_loader, lr=LR, device=DEVICE)"
>>>>>>> 3fd1e04 (clean files)
      ]
    },
    {
      "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
      "execution_count": 20,
=======
      "source": [
        "y_pred = get_predictions(model1, test_loader)\n",
        "accuracy_score(y_pred, y_test), f1_score(y_pred, y_test), balanced_accuracy_score(y_pred, y_test)"
      ],
>>>>>>> 88c8b7e (fine tuning strategies)
=======
      "execution_count": 20,
>>>>>>> 3fd1e04 (clean files)
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9P97xascSGb1",
        "outputId": "fb9be372-3e90-4b77-9476-644202c9684c"
      },
<<<<<<< HEAD
<<<<<<< HEAD
      "outputs": [
        {
=======
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
>>>>>>> 88c8b7e (fine tuning strategies)
=======
      "outputs": [
        {
>>>>>>> 3fd1e04 (clean files)
          "data": {
            "text/plain": [
              "(0.9790450017176228, 0.9854727316027625, 0.9730535256286329)"
            ]
          },
<<<<<<< HEAD
<<<<<<< HEAD
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_pred = get_predictions(model1, test_loader)\n",
        "accuracy_score(y_pred, y_test), f1_score(y_pred, y_test), balanced_accuracy_score(y_pred, y_test)"
=======
=======
          "execution_count": 20,
>>>>>>> 3fd1e04 (clean files)
          "metadata": {},
          "output_type": "execute_result"
        }
<<<<<<< HEAD
>>>>>>> 88c8b7e (fine tuning strategies)
=======
      ],
      "source": [
        "y_pred = get_predictions(model1, test_loader)\n",
        "accuracy_score(y_pred, y_test), f1_score(y_pred, y_test), balanced_accuracy_score(y_pred, y_test)"
>>>>>>> 3fd1e04 (clean files)
      ]
    },
    {
      "cell_type": "markdown",
<<<<<<< HEAD
<<<<<<< HEAD
      "metadata": {
        "id": "6vTFQyC1G0jv"
      },
      "source": [
        "### 2 Train the entire model on the PTB dataset (encoder + output layers).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "F4mK7xmWG3dU"
      },
      "outputs": [],
=======
      "source": [
        "### 2 Train the entire model on the PTB dataset (encoder + output layers).\n"
      ],
=======
>>>>>>> 3fd1e04 (clean files)
      "metadata": {
        "id": "6vTFQyC1G0jv"
      },
      "source": [
        "### 2 Train the entire model on the PTB dataset (encoder + output layers).\n"
      ]
    },
    {
      "cell_type": "code",
<<<<<<< HEAD
>>>>>>> 88c8b7e (fine tuning strategies)
=======
      "execution_count": 21,
      "metadata": {
        "id": "F4mK7xmWG3dU"
      },
      "outputs": [],
>>>>>>> 3fd1e04 (clean files)
      "source": [
        "encoder = get_encoder()\n",
        "model2 = TimeSeriesClassifier(encoder=encoder, hidden_size=hidden_size, layer_sizes=[hidden_size, int(hidden_size/2)], dropout_prob=0.05)\n",
        "model2 = model2.to(DEVICE)"
<<<<<<< HEAD
<<<<<<< HEAD
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
=======
      ],
      "metadata": {
        "id": "F4mK7xmWG3dU"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_clf(model=model2, epochs=N_EPOCHS, batch_size=BATCH_SIZE, train_loader=train_loader, lr=LR, device=DEVICE)"
      ],
>>>>>>> 88c8b7e (fine tuning strategies)
=======
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
>>>>>>> 3fd1e04 (clean files)
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ugrwHZ4SkfS",
        "outputId": "bfdfbe28-5122-4a7d-c483-ac09519042dd"
      },
<<<<<<< HEAD
<<<<<<< HEAD
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
=======
      "execution_count": 22,
=======
>>>>>>> 3fd1e04 (clean files)
      "outputs": [
        {
          "name": "stdout",
<<<<<<< HEAD
>>>>>>> 88c8b7e (fine tuning strategies)
=======
          "output_type": "stream",
>>>>>>> 3fd1e04 (clean files)
          "text": [
            "epoch 0 train loss 58.44984345138073\n",
            "epoch 1 train loss 31.222764033824205\n",
            "epoch 2 train loss 18.95925211161375\n",
            "epoch 3 train loss 13.899778578430414\n",
            "epoch 4 train loss 10.834311350248754\n",
            "epoch 5 train loss 9.016216847579926\n",
            "epoch 6 train loss 7.170307659078389\n",
            "epoch 7 train loss 5.872288563055918\n",
            "epoch 8 train loss 5.314514721278101\n",
            "epoch 9 train loss 4.31299625034444\n",
            "epoch 10 train loss 4.105835499591194\n",
            "epoch 11 train loss 3.18188052426558\n",
            "epoch 12 train loss 2.474600304441992\n",
            "epoch 13 train loss 2.2831439460860565\n",
            "epoch 14 train loss 1.8986303019628394\n"
          ]
        }
<<<<<<< HEAD
<<<<<<< HEAD
      ],
      "source": [
        "train_clf(model=model2, epochs=N_EPOCHS, batch_size=BATCH_SIZE, train_loader=train_loader, lr=LR, device=DEVICE)"
=======
>>>>>>> 88c8b7e (fine tuning strategies)
=======
      ],
      "source": [
        "train_clf(model=model2, epochs=N_EPOCHS, batch_size=BATCH_SIZE, train_loader=train_loader, lr=LR, device=DEVICE)"
>>>>>>> 3fd1e04 (clean files)
      ]
    },
    {
      "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
      "execution_count": 23,
=======
      "source": [
        "y_pred = get_predictions(model2, test_loader)\n",
        "accuracy_score(y_pred, y_test), f1_score(y_pred, y_test), balanced_accuracy_score(y_pred, y_test)"
      ],
>>>>>>> 88c8b7e (fine tuning strategies)
=======
      "execution_count": 23,
>>>>>>> 3fd1e04 (clean files)
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bYdM8D0hSodj",
        "outputId": "5fe1f786-46fc-4ed8-c3c9-08d6206e9737"
      },
<<<<<<< HEAD
<<<<<<< HEAD
      "outputs": [
        {
=======
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
>>>>>>> 88c8b7e (fine tuning strategies)
=======
      "outputs": [
        {
>>>>>>> 3fd1e04 (clean files)
          "data": {
            "text/plain": [
              "(0.9876331157677773, 0.9914285714285714, 0.9838867216126881)"
            ]
          },
<<<<<<< HEAD
<<<<<<< HEAD
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_pred = get_predictions(model2, test_loader)\n",
        "accuracy_score(y_pred, y_test), f1_score(y_pred, y_test), balanced_accuracy_score(y_pred, y_test)"
=======
=======
          "execution_count": 23,
>>>>>>> 3fd1e04 (clean files)
          "metadata": {},
          "output_type": "execute_result"
        }
<<<<<<< HEAD
>>>>>>> 88c8b7e (fine tuning strategies)
=======
      ],
      "source": [
        "y_pred = get_predictions(model2, test_loader)\n",
        "accuracy_score(y_pred, y_test), f1_score(y_pred, y_test), balanced_accuracy_score(y_pred, y_test)"
>>>>>>> 3fd1e04 (clean files)
      ]
    },
    {
      "cell_type": "markdown",
<<<<<<< HEAD
<<<<<<< HEAD
      "metadata": {
        "id": "pG6sXUZnSbjE"
      },
      "source": [
        "### 3 First, train the output layers, then unfreeze and train the entire joint model in two separate stages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "1vFUaE74Sdxe"
      },
      "outputs": [],
=======
      "source": [
        "### 3 First, train the output layers, then unfreeze and train the entire joint model in two separate stages."
      ],
=======
>>>>>>> 3fd1e04 (clean files)
      "metadata": {
        "id": "pG6sXUZnSbjE"
      },
      "source": [
        "### 3 First, train the output layers, then unfreeze and train the entire joint model in two separate stages."
      ]
    },
    {
      "cell_type": "code",
<<<<<<< HEAD
>>>>>>> 88c8b7e (fine tuning strategies)
=======
      "execution_count": 24,
      "metadata": {
        "id": "1vFUaE74Sdxe"
      },
      "outputs": [],
>>>>>>> 3fd1e04 (clean files)
      "source": [
        "encoder = get_encoder()\n",
        "model3 = TimeSeriesClassifier(encoder=encoder, hidden_size=hidden_size, layer_sizes=[hidden_size, int(hidden_size/2)], dropout_prob=0.05)\n",
        "model3 = model3.to(DEVICE)\n",
        "\n",
        "# freeze encoder\n",
        "for param in model3.encoder.parameters():\n",
        "    param.requires_grad = False"
<<<<<<< HEAD
<<<<<<< HEAD
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
=======
      ],
      "metadata": {
        "id": "1vFUaE74Sdxe"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_clf(model=model3, epochs=N_EPOCHS, batch_size=BATCH_SIZE, train_loader=train_loader, lr=LR, device=DEVICE)"
      ],
>>>>>>> 88c8b7e (fine tuning strategies)
=======
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
>>>>>>> 3fd1e04 (clean files)
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6i98O6-RTDrx",
        "outputId": "55a1ed32-a911-4225-d075-7bb2821c5330"
      },
<<<<<<< HEAD
<<<<<<< HEAD
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
=======
      "execution_count": 25,
=======
>>>>>>> 3fd1e04 (clean files)
      "outputs": [
        {
          "name": "stdout",
<<<<<<< HEAD
>>>>>>> 88c8b7e (fine tuning strategies)
=======
          "output_type": "stream",
>>>>>>> 3fd1e04 (clean files)
          "text": [
            "epoch 0 train loss 61.76587425172329\n",
            "epoch 1 train loss 42.57281215488911\n",
            "epoch 2 train loss 33.46751194447279\n",
            "epoch 3 train loss 27.857324045151472\n",
            "epoch 4 train loss 23.806398563086987\n",
            "epoch 5 train loss 20.227888394147158\n",
            "epoch 6 train loss 17.817237256094813\n",
            "epoch 7 train loss 16.13025980256498\n",
            "epoch 8 train loss 14.08093883562833\n",
            "epoch 9 train loss 13.292798305861652\n",
            "epoch 10 train loss 12.149187461473048\n",
            "epoch 11 train loss 11.017091347835958\n",
            "epoch 12 train loss 10.305554018355906\n",
            "epoch 13 train loss 9.786439585499465\n",
            "epoch 14 train loss 8.953765538986772\n"
          ]
        }
<<<<<<< HEAD
<<<<<<< HEAD
      ],
      "source": [
        "train_clf(model=model3, epochs=N_EPOCHS, batch_size=BATCH_SIZE, train_loader=train_loader, lr=LR, device=DEVICE)"
=======
>>>>>>> 88c8b7e (fine tuning strategies)
=======
      ],
      "source": [
        "train_clf(model=model3, epochs=N_EPOCHS, batch_size=BATCH_SIZE, train_loader=train_loader, lr=LR, device=DEVICE)"
>>>>>>> 3fd1e04 (clean files)
      ]
    },
    {
      "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
      "execution_count": 26,
=======
      "source": [
        "# unfreeze encoder\n",
        "for param in model3.encoder.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "train_clf(model=model3, epochs=N_EPOCHS, batch_size=BATCH_SIZE, train_loader=train_loader, lr=LR, device=DEVICE)"
      ],
>>>>>>> 88c8b7e (fine tuning strategies)
=======
      "execution_count": 26,
>>>>>>> 3fd1e04 (clean files)
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kIk2ndscTFxr",
        "outputId": "6ad8d6ec-e265-4206-e225-2b580eed40e2"
      },
<<<<<<< HEAD
<<<<<<< HEAD
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
=======
      "execution_count": 26,
=======
>>>>>>> 3fd1e04 (clean files)
      "outputs": [
        {
          "name": "stdout",
<<<<<<< HEAD
>>>>>>> 88c8b7e (fine tuning strategies)
=======
          "output_type": "stream",
>>>>>>> 3fd1e04 (clean files)
          "text": [
            "epoch 0 train loss 9.200908442027867\n",
            "epoch 1 train loss 7.348598421085626\n",
            "epoch 2 train loss 5.87915239459835\n",
            "epoch 3 train loss 5.552797793643549\n",
            "epoch 4 train loss 4.629614478442818\n",
            "epoch 5 train loss 4.244658805779181\n",
            "epoch 6 train loss 3.6170187590178102\n",
            "epoch 7 train loss 2.9423350353026763\n",
            "epoch 8 train loss 2.623243553331122\n",
            "epoch 9 train loss 1.944461294071516\n",
            "epoch 10 train loss 2.4594217453850433\n",
            "epoch 11 train loss 2.714545352413552\n",
            "epoch 12 train loss 1.804196494515054\n",
            "epoch 13 train loss 1.5204778313200222\n",
            "epoch 14 train loss 1.0071359684952768\n"
          ]
        }
<<<<<<< HEAD
<<<<<<< HEAD
=======
>>>>>>> 3fd1e04 (clean files)
      ],
      "source": [
        "# unfreeze encoder\n",
        "for param in model3.encoder.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "train_clf(model=model3, epochs=N_EPOCHS, batch_size=BATCH_SIZE, train_loader=train_loader, lr=LR, device=DEVICE)"
<<<<<<< HEAD
=======
>>>>>>> 88c8b7e (fine tuning strategies)
=======
>>>>>>> 3fd1e04 (clean files)
      ]
    },
    {
      "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
      "execution_count": 27,
=======
      "source": [
        "y_pred = get_predictions(model3, test_loader)\n",
        "accuracy_score(y_pred, y_test), f1_score(y_pred, y_test), balanced_accuracy_score(y_pred, y_test)"
      ],
>>>>>>> 88c8b7e (fine tuning strategies)
=======
      "execution_count": 27,
>>>>>>> 3fd1e04 (clean files)
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dEklDtHeTS-B",
        "outputId": "16185890-75e5-4f22-ff23-3ba7776d7908"
      },
<<<<<<< HEAD
<<<<<<< HEAD
      "outputs": [
        {
=======
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
>>>>>>> 88c8b7e (fine tuning strategies)
=======
      "outputs": [
        {
>>>>>>> 3fd1e04 (clean files)
          "data": {
            "text/plain": [
              "(0.9886636894537959, 0.9921559305918707, 0.9864192546400806)"
            ]
          },
<<<<<<< HEAD
<<<<<<< HEAD
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_pred = get_predictions(model3, test_loader)\n",
        "accuracy_score(y_pred, y_test), f1_score(y_pred, y_test), balanced_accuracy_score(y_pred, y_test)"
=======
=======
          "execution_count": 27,
>>>>>>> 3fd1e04 (clean files)
          "metadata": {},
          "output_type": "execute_result"
        }
<<<<<<< HEAD
>>>>>>> 88c8b7e (fine tuning strategies)
=======
      ],
      "source": [
        "y_pred = get_predictions(model3, test_loader)\n",
        "accuracy_score(y_pred, y_test), f1_score(y_pred, y_test), balanced_accuracy_score(y_pred, y_test)"
>>>>>>> 3fd1e04 (clean files)
      ]
    }
  ],
  "metadata": {
<<<<<<< HEAD
<<<<<<< HEAD
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
=======
    "language_info": {
      "name": "python"
    },
=======
    "accelerator": "GPU",
>>>>>>> 3fd1e04 (clean files)
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
<<<<<<< HEAD
>>>>>>> 88c8b7e (fine tuning strategies)
=======
>>>>>>> 3fd1e04 (clean files)
