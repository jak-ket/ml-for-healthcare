{
  "cells": [
    {
      "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
=======
>>>>>>> 3fd1e04 (clean files)
      "execution_count": 2,
      "metadata": {
        "id": "2sJWPWow9SXF"
      },
      "outputs": [],
<<<<<<< HEAD
      "source": [
=======
      "source": [
        "import multiprocessing\n",
>>>>>>> 88c8b7e (fine tuning strategies)
=======
      "source": [
>>>>>>> 3fd1e04 (clean files)
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch import optim\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import accuracy_score, f1_score, balanced_accuracy_score\n",
        "from lightgbm import LGBMClassifier\n",
<<<<<<< HEAD
<<<<<<< HEAD
        "from torch.utils.data import DataLoader, TensorDataset"
=======
        "from tqdm import tqdm\n",
        "from torch.utils.data import Dataset, DataLoader, TensorDataset"
<<<<<<< HEAD
      ],
      "metadata": {
        "id": "2sJWPWow9SXF"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y008k8oI85X0",
        "outputId": "cb7253cd-1eb5-4309-ae6e-c7b8d5da6329"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive\n"
          ]
        }
>>>>>>> 88c8b7e (fine tuning strategies)
=======
>>>>>>> 3fd1e04 (clean files)
=======
        "from torch.utils.data import DataLoader, TensorDataset"
>>>>>>> 9ab9bf1 (clean up imports)
      ]
    },
    {
      "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
      "execution_count": 6,
      "metadata": {
        "id": "C4nwljn51wxw"
      },
      "outputs": [],
      "source": [
        "from encoder import AutoEncoderCnn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "HJT0iuIW-9Ua"
      },
      "outputs": [],
      "source": [
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
=======
      "source": [
        "import os\n",
        "os.chdir(\"/gdrive/MyDrive/ml-for-healthcare\")"
      ],
      "metadata": {
        "id": "YzPKOi139VDu"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from encoder import AutoEncoderCnn"
      ],
=======
      "execution_count": 6,
>>>>>>> 3fd1e04 (clean files)
      "metadata": {
        "id": "C4nwljn51wxw"
      },
      "outputs": [],
      "source": [
        "from encoder import AutoEncoderCnn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "HJT0iuIW-9Ua"
      },
<<<<<<< HEAD
      "execution_count": 7,
      "outputs": []
>>>>>>> 88c8b7e (fine tuning strategies)
=======
      "outputs": [],
      "source": [
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
>>>>>>> 3fd1e04 (clean files)
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IxGUtYNR8MDr"
      },
      "source": [
        "# Q4: Finetuning Strategies using Encoder from Q2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s7m76Gt58MDu"
      },
      "source": [
        "## 1. Classic ML\n",
        "Similar to Q3,\n",
        "- obtain representations for the PTB dataset by feeding the dataset through the pre-trained encoder\n",
        "- Use a classic ML method from Part 1 to train and test for the PTB task using these representations"
      ]
    },
    {
      "cell_type": "markdown",
<<<<<<< HEAD
<<<<<<< HEAD
      "metadata": {
        "id": "0vvr57tk9pWi"
      },
      "source": [
        "### Encode dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q9oCJsU797yf"
      },
      "outputs": [],
=======
      "source": [
        "### Encode dataset"
      ],
=======
>>>>>>> 3fd1e04 (clean files)
      "metadata": {
        "id": "0vvr57tk9pWi"
      },
      "source": [
        "### Encode dataset"
      ]
    },
    {
      "cell_type": "code",
<<<<<<< HEAD
>>>>>>> 88c8b7e (fine tuning strategies)
=======
      "execution_count": null,
      "metadata": {
        "id": "Q9oCJsU797yf"
      },
      "outputs": [],
>>>>>>> 3fd1e04 (clean files)
      "source": [
        "# load data\n",
        "train = pd.read_csv(\"ptbdb_train.csv\", header=None)\n",
        "test = pd.read_csv(\"ptbdb_test.csv\", header=None)\n",
        "\n",
        "X_train = train.drop(187, axis=1)\n",
        "X_test = test.drop(187, axis=1)\n",
        "\n",
        "y_train = train[187]\n",
        "y_test = test[187]"
<<<<<<< HEAD
<<<<<<< HEAD
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "6utNGyAz9ojJ"
      },
      "outputs": [],
=======
      ],
      "metadata": {
        "id": "Q9oCJsU797yf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
>>>>>>> 88c8b7e (fine tuning strategies)
=======
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "6utNGyAz9ojJ"
      },
      "outputs": [],
>>>>>>> 3fd1e04 (clean files)
      "source": [
        "# load autoencoder model\n",
        "ae = AutoEncoderCnn()\n",
        "ae.to(DEVICE)\n",
        "ae.load_state_dict(torch.load(\"encoder_model.pth\"))"
<<<<<<< HEAD
<<<<<<< HEAD
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VccPXDJ595iP"
      },
      "outputs": [],
=======
      ],
      "metadata": {
        "id": "6utNGyAz9ojJ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
>>>>>>> 88c8b7e (fine tuning strategies)
=======
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VccPXDJ595iP"
      },
      "outputs": [],
>>>>>>> 3fd1e04 (clean files)
      "source": [
        "# feed data through encoder model to get embeddings\n",
        "\n",
        "def get_encodings(model, X, device, batchsize=64):\n",
        "  X_tensor = torch.tensor(X.values, dtype=torch.float32)\n",
        "  X_dataloader = DataLoader(X_tensor, batch_size=batchsize, shuffle=False)\n",
        "\n",
        "  encodings = []\n",
        "\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    for x_batch in X_dataloader:\n",
        "      x_batch = x_batch.unsqueeze(1)\n",
        "      x_batch = x_batch.to(device)\n",
        "      x_batch_encoding = model(x_batch)\n",
        "      encodings.append(x_batch_encoding.detach().cpu().numpy())\n",
        "\n",
        "  return encodings\n",
        "\n",
        "encoder = ae.encoder\n",
        "X_train_encodings = get_encodings(model=encoder, X=X_train, device=DEVICE)\n",
        "X_test_encodings = get_encodings(model=encoder, X=X_test, device=DEVICE)"
<<<<<<< HEAD
<<<<<<< HEAD
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "unFlPfY2DGu8"
      },
      "outputs": [],
=======
      ],
      "metadata": {
        "id": "VccPXDJ595iP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
>>>>>>> 88c8b7e (fine tuning strategies)
=======
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "unFlPfY2DGu8"
      },
      "outputs": [],
>>>>>>> 3fd1e04 (clean files)
      "source": [
        "# create numpy matrices from list of batches\n",
        "X_train_encodings = np.vstack(X_train_encodings)\n",
        "X_test_encodings = np.vstack(X_test_encodings)"
<<<<<<< HEAD
<<<<<<< HEAD
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3zOLOP19zVh"
      },
      "source": [
        "### Train and Test classic ML model"
      ]
=======
      ],
      "metadata": {
        "id": "unFlPfY2DGu8"
      },
      "execution_count": null,
      "outputs": []
=======
      ]
>>>>>>> 3fd1e04 (clean files)
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3zOLOP19zVh"
<<<<<<< HEAD
      }
>>>>>>> 88c8b7e (fine tuning strategies)
=======
      },
      "source": [
        "### Train and Test classic ML model"
      ]
>>>>>>> 3fd1e04 (clean files)
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
<<<<<<< HEAD
<<<<<<< HEAD
=======
        "vscode": {
          "languageId": "plaintext"
        },
>>>>>>> 88c8b7e (fine tuning strategies)
=======
>>>>>>> 3fd1e04 (clean files)
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "collapsed": true,
        "id": "m4IFsOje8MDu",
<<<<<<< HEAD
<<<<<<< HEAD
=======
>>>>>>> 3fd1e04 (clean files)
        "outputId": "ef9d5821-d61d-4d74-a483-17500e3d8eae",
        "vscode": {
          "languageId": "plaintext"
        }
<<<<<<< HEAD
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMClassifier(max_depth=9, n_estimators=500, verbose=-1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(max_depth=9, n_estimators=500, verbose=-1)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "LGBMClassifier(max_depth=9, n_estimators=500, verbose=-1)"
            ]
          },
          "execution_count": 155,
          "metadata": {},
          "output_type": "execute_result"
=======
        "outputId": "ef9d5821-d61d-4d74-a483-17500e3d8eae"
=======
>>>>>>> 3fd1e04 (clean files)
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMClassifier(max_depth=9, n_estimators=500, verbose=-1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(max_depth=9, n_estimators=500, verbose=-1)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "LGBMClassifier(max_depth=9, n_estimators=500, verbose=-1)"
            ]
          },
          "execution_count": 155,
          "metadata": {},
<<<<<<< HEAD
          "execution_count": 155
>>>>>>> 88c8b7e (fine tuning strategies)
=======
          "output_type": "execute_result"
>>>>>>> 3fd1e04 (clean files)
        }
      ],
      "source": [
        "# train classic ML model\n",
        "clf = LGBMClassifier(verbose=-1, n_estimators=500, learning_rate=0.1, max_depth=9) # choose parameters from part 1\n",
        "clf.fit(X_train_encodings, y_train)"
      ]
    },
    {
      "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
=======
>>>>>>> 3fd1e04 (clean files)
      "execution_count": null,
      "metadata": {
        "id": "xOvbYuSzbsvz"
      },
      "outputs": [],
<<<<<<< HEAD
=======
>>>>>>> 88c8b7e (fine tuning strategies)
=======
>>>>>>> 3fd1e04 (clean files)
      "source": [
        "# test performance\n",
        "y_pred = clf.predict(X_test_encodings)\n",
        "accuracy_score(y_pred, y_test), f1_score(y_pred, y_test), balanced_accuracy_score(y_pred, y_test)"
<<<<<<< HEAD
<<<<<<< HEAD
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 116
        },
        "id": "YAdhKQqOXpwz",
        "outputId": "4b635986-8789-489d-f1bd-a6ebd1c12c26"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=LGBMClassifier(verbose=-1),\n",
              "             param_grid={&#x27;learning_rate&#x27;: [0.01, 0.1, 1],\n",
              "                         &#x27;max_depth&#x27;: [3, 5, 7, 9],\n",
              "                         &#x27;n_estimators&#x27;: [100, 200, 300, 400, 500]},\n",
              "             scoring=&#x27;f1&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=LGBMClassifier(verbose=-1),\n",
              "             param_grid={&#x27;learning_rate&#x27;: [0.01, 0.1, 1],\n",
              "                         &#x27;max_depth&#x27;: [3, 5, 7, 9],\n",
              "                         &#x27;n_estimators&#x27;: [100, 200, 300, 400, 500]},\n",
              "             scoring=&#x27;f1&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(verbose=-1)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(verbose=-1)</pre></div></div></div></div></div></div></div></div></div></div>"
            ],
            "text/plain": [
              "GridSearchCV(cv=5, estimator=LGBMClassifier(verbose=-1),\n",
              "             param_grid={'learning_rate': [0.01, 0.1, 1],\n",
              "                         'max_depth': [3, 5, 7, 9],\n",
              "                         'n_estimators': [100, 200, 300, 400, 500]},\n",
              "             scoring='f1')"
            ]
          },
          "execution_count": 165,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
=======
      ],
      "metadata": {
        "id": "xOvbYuSzbsvz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
>>>>>>> 88c8b7e (fine tuning strategies)
      "source": [
        "# train classic ML model\n",
        "param_grid = {'n_estimators': [100, 200, 300, 400, 500],\n",
        "              'learning_rate': [0.01, 0.1, 1],\n",
        "              'max_depth': [3, 5, 7, 9]}\n",
        "\n",
        "clf = LGBMClassifier(verbose=-1)\n",
        "\n",
        "grid_search = GridSearchCV(clf, param_grid, cv=5, scoring='f1')\n",
        "grid_search.fit(X_train_encodings, y_train)"
<<<<<<< HEAD
=======
      ],
=======
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
>>>>>>> 3fd1e04 (clean files)
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 116
        },
        "id": "YAdhKQqOXpwz",
        "outputId": "4b635986-8789-489d-f1bd-a6ebd1c12c26"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=LGBMClassifier(verbose=-1),\n",
              "             param_grid={&#x27;learning_rate&#x27;: [0.01, 0.1, 1],\n",
              "                         &#x27;max_depth&#x27;: [3, 5, 7, 9],\n",
              "                         &#x27;n_estimators&#x27;: [100, 200, 300, 400, 500]},\n",
              "             scoring=&#x27;f1&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=LGBMClassifier(verbose=-1),\n",
              "             param_grid={&#x27;learning_rate&#x27;: [0.01, 0.1, 1],\n",
              "                         &#x27;max_depth&#x27;: [3, 5, 7, 9],\n",
              "                         &#x27;n_estimators&#x27;: [100, 200, 300, 400, 500]},\n",
              "             scoring=&#x27;f1&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(verbose=-1)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(verbose=-1)</pre></div></div></div></div></div></div></div></div></div></div>"
            ],
            "text/plain": [
              "GridSearchCV(cv=5, estimator=LGBMClassifier(verbose=-1),\n",
              "             param_grid={'learning_rate': [0.01, 0.1, 1],\n",
              "                         'max_depth': [3, 5, 7, 9],\n",
              "                         'n_estimators': [100, 200, 300, 400, 500]},\n",
              "             scoring='f1')"
            ]
          },
          "execution_count": 165,
          "metadata": {},
          "output_type": "execute_result"
        }
<<<<<<< HEAD
>>>>>>> 88c8b7e (fine tuning strategies)
=======
      ],
      "source": [
        "# train classic ML model\n",
        "param_grid = {'n_estimators': [100, 200, 300, 400, 500],\n",
        "              'learning_rate': [0.01, 0.1, 1],\n",
        "              'max_depth': [3, 5, 7, 9]}\n",
        "\n",
        "clf = LGBMClassifier(verbose=-1)\n",
        "\n",
        "grid_search = GridSearchCV(clf, param_grid, cv=5, scoring='f1')\n",
        "grid_search.fit(X_train_encodings, y_train)"
>>>>>>> 3fd1e04 (clean files)
      ]
    },
    {
      "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
      "execution_count": null,
=======
      "source": [
        "print(\"Best parameters: {}\".format(grid_search.best_params_))"
      ],
>>>>>>> 88c8b7e (fine tuning strategies)
=======
      "execution_count": null,
>>>>>>> 3fd1e04 (clean files)
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g2QB1JoReIq9",
        "outputId": "6bb23e0d-d491-404f-ff07-683f44088518"
      },
<<<<<<< HEAD
<<<<<<< HEAD
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
=======
      "execution_count": null,
=======
>>>>>>> 3fd1e04 (clean files)
      "outputs": [
        {
          "name": "stdout",
<<<<<<< HEAD
>>>>>>> 88c8b7e (fine tuning strategies)
=======
          "output_type": "stream",
>>>>>>> 3fd1e04 (clean files)
          "text": [
            "Best parameters: {'learning_rate': 0.1, 'max_depth': 9, 'n_estimators': 500}\n"
          ]
        }
<<<<<<< HEAD
<<<<<<< HEAD
      ],
      "source": [
        "print(\"Best parameters: {}\".format(grid_search.best_params_))"
=======
>>>>>>> 88c8b7e (fine tuning strategies)
=======
      ],
      "source": [
        "print(\"Best parameters: {}\".format(grid_search.best_params_))"
>>>>>>> 3fd1e04 (clean files)
      ]
    },
    {
      "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
      "execution_count": null,
=======
      "source": [
        "# test performance\n",
        "y_pred = grid_search.predict(X_test_encodings)\n",
        "accuracy_score(y_pred, y_test), f1_score(y_pred, y_test), balanced_accuracy_score(y_pred, y_test)"
      ],
>>>>>>> 88c8b7e (fine tuning strategies)
=======
      "execution_count": null,
>>>>>>> 3fd1e04 (clean files)
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kd8OPEoU-EY8",
        "outputId": "4b358b82-9d88-4954-ddde-9aea4e4e6dba"
      },
<<<<<<< HEAD
<<<<<<< HEAD
      "outputs": [
        {
=======
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
>>>>>>> 88c8b7e (fine tuning strategies)
=======
      "outputs": [
        {
>>>>>>> 3fd1e04 (clean files)
          "data": {
            "text/plain": [
              "(0.971830985915493, 0.9805410536307546, 0.9665816882845981)"
            ]
          },
<<<<<<< HEAD
<<<<<<< HEAD
          "execution_count": 166,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# test performance\n",
        "y_pred = grid_search.predict(X_test_encodings)\n",
        "accuracy_score(y_pred, y_test), f1_score(y_pred, y_test), balanced_accuracy_score(y_pred, y_test)"
=======
=======
          "execution_count": 166,
>>>>>>> 3fd1e04 (clean files)
          "metadata": {},
          "output_type": "execute_result"
        }
<<<<<<< HEAD
>>>>>>> 88c8b7e (fine tuning strategies)
=======
      ],
      "source": [
        "# test performance\n",
        "y_pred = grid_search.predict(X_test_encodings)\n",
        "accuracy_score(y_pred, y_test), f1_score(y_pred, y_test), balanced_accuracy_score(y_pred, y_test)"
>>>>>>> 3fd1e04 (clean files)
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0KCyZnYX8MDw"
      },
      "source": [
        "## 2. ANNs\n",
        "Add output layer(s) for the PTB binary class to your encoder model. Implement the following finetuning strategies\n",
        "- Train the output layer(s) only on the PTB dataset, freezing the encoder\n",
        "- Train the entire model on the PTB dataset (encoder + output layers).\n",
        "- First, train the output layers, then unfreeze and train the entire joint model in two\n",
        "separate stages."
      ]
    },
    {
      "cell_type": "markdown",
<<<<<<< HEAD
<<<<<<< HEAD
      "metadata": {
        "id": "ZZKUMssfG8pA"
      },
      "source": [
        "### Add output layer(s) for the PTB binary class to your encoder model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "94mCzbnAG7pk"
      },
      "outputs": [],
=======
      "source": [
        "### Add output layer(s) for the PTB binary class to your encoder model."
      ],
=======
>>>>>>> 3fd1e04 (clean files)
      "metadata": {
        "id": "ZZKUMssfG8pA"
      },
      "source": [
        "### Add output layer(s) for the PTB binary class to your encoder model."
      ]
    },
    {
      "cell_type": "code",
<<<<<<< HEAD
>>>>>>> 88c8b7e (fine tuning strategies)
=======
      "execution_count": null,
      "metadata": {
        "id": "94mCzbnAG7pk"
      },
      "outputs": [],
>>>>>>> 3fd1e04 (clean files)
      "source": [
        "class TimeSeriesClassifier(torch.nn.Module):\n",
        "  def __init__(self, encoder, hidden_size, layer_sizes, dropout_prob):\n",
        "    super(TimeSeriesClassifier, self).__init__()\n",
        "    self.encoder = encoder\n",
        "    self.classifier = torch.nn.Sequential(\n",
        "        torch.nn.Linear(hidden_size, layer_sizes[0]),\n",
        "        torch.nn.ReLU(),\n",
        "        torch.nn.Dropout(dropout_prob),\n",
        "        torch.nn.Linear(layer_sizes[0], layer_sizes[1]),\n",
        "        torch.nn.ReLU(),\n",
        "        torch.nn.Dropout(dropout_prob),\n",
        "        torch.nn.Linear(layer_sizes[1], 1),\n",
        "        torch.nn.Sigmoid()\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.classifier(self.encoder(x))"
<<<<<<< HEAD
<<<<<<< HEAD
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L1kaYlTPLFo5"
      },
      "outputs": [],
=======
      ],
      "metadata": {
        "id": "94mCzbnAG7pk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
>>>>>>> 88c8b7e (fine tuning strategies)
=======
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L1kaYlTPLFo5"
      },
      "outputs": [],
>>>>>>> 3fd1e04 (clean files)
      "source": [
        "def train_clf(model, epochs, batch_size, train_loader, lr, device):\n",
        "  criterion = torch.nn.BCELoss()\n",
        "  optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "\n",
        "      model.train()\n",
        "\n",
        "      epoch_loss = 0\n",
        "\n",
        "      for X, y in train_loader:\n",
        "\n",
        "          X = X.to(DEVICE)\n",
        "          y = y.to(DEVICE)\n",
        "\n",
        "          y_pred = model(X.unsqueeze(1))\n",
        "\n",
        "          # loss = criterion(y_pred, batch[\"score\"])\n",
        "          loss = criterion(y_pred.squeeze(1), y)\n",
        "\n",
        "          # backward pass\n",
        "          optimizer.zero_grad()\n",
        "          loss.backward()\n",
        "\n",
        "          # update weights\n",
        "          optimizer.step()\n",
        "\n",
        "          epoch_loss += loss.item()\n",
        "\n",
        "      print(f\"epoch {epoch} train loss {epoch_loss}\")"
<<<<<<< HEAD
<<<<<<< HEAD
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t__9qS3cQn7q"
      },
      "outputs": [],
=======
      ],
      "metadata": {
        "id": "L1kaYlTPLFo5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
>>>>>>> 88c8b7e (fine tuning strategies)
=======
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t__9qS3cQn7q"
      },
      "outputs": [],
>>>>>>> 3fd1e04 (clean files)
      "source": [
        "def get_predictions(model, test_loader):\n",
        "  y_preds = []\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    for X, y in test_loader:\n",
        "      X = X.to(DEVICE)\n",
        "      y = y.to(DEVICE)\n",
        "      y_pred = model(X.unsqueeze(1))\n",
        "      y_preds.append(y_pred.detach().cpu().numpy())\n",
        "  return np.round(np.vstack(y_preds))"
<<<<<<< HEAD
<<<<<<< HEAD
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oPnTZhF7NZAP"
      },
      "outputs": [],
=======
      ],
      "metadata": {
        "id": "t__9qS3cQn7q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
>>>>>>> 88c8b7e (fine tuning strategies)
=======
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oPnTZhF7NZAP"
      },
      "outputs": [],
>>>>>>> 3fd1e04 (clean files)
      "source": [
        "train_dataset = TensorDataset(torch.tensor(X_train.to_numpy(), dtype=torch.float32), torch.tensor(y_train, dtype=torch.float32))\n",
        "test_dataset = TensorDataset(torch.tensor(X_test.to_numpy(), dtype=torch.float32), torch.tensor(y_test, dtype=torch.float32))\n",
        "\n",
        "BATCH_SIZE = 64\n",
        "train_loader = DataLoader(train_dataset, shuffle=False, batch_size=BATCH_SIZE, pin_memory=True)\n",
        "test_loader = DataLoader(test_dataset, shuffle=False, batch_size=BATCH_SIZE, pin_memory=True)"
<<<<<<< HEAD
<<<<<<< HEAD
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_V3dR33vPWJ0"
      },
      "outputs": [],
=======
      ],
      "metadata": {
        "id": "oPnTZhF7NZAP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
>>>>>>> 88c8b7e (fine tuning strategies)
=======
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_V3dR33vPWJ0"
      },
      "outputs": [],
>>>>>>> 3fd1e04 (clean files)
      "source": [
        "N_EPOCHS = 30\n",
        "LR = 0.0003\n",
        "hidden_size = 128 # bottleneck dimension of encoder"
<<<<<<< HEAD
<<<<<<< HEAD
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZvhU1RYGuR9"
      },
      "source": [
        "### 1 Train the output layer(s) only on the PTB dataset, freezing the encoder"
      ]
=======
      ],
      "metadata": {
        "id": "_V3dR33vPWJ0"
      },
      "execution_count": null,
      "outputs": []
=======
      ]
>>>>>>> 3fd1e04 (clean files)
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZvhU1RYGuR9"
<<<<<<< HEAD
      }
>>>>>>> 88c8b7e (fine tuning strategies)
=======
      },
      "source": [
        "### 1 Train the output layer(s) only on the PTB dataset, freezing the encoder"
      ]
>>>>>>> 3fd1e04 (clean files)
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
<<<<<<< HEAD
<<<<<<< HEAD
        "id": "3i5Ki0Fw8MDx",
        "vscode": {
          "languageId": "plaintext"
        }
=======
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "3i5Ki0Fw8MDx"
>>>>>>> 88c8b7e (fine tuning strategies)
=======
        "id": "3i5Ki0Fw8MDx",
        "vscode": {
          "languageId": "plaintext"
        }
>>>>>>> 3fd1e04 (clean files)
      },
      "outputs": [],
      "source": [
        "model1 = TimeSeriesClassifier(encoder=encoder, hidden_size=hidden_size, layer_sizes=[hidden_size, int(hidden_size/2)], dropout_prob=0.05)\n",
        "model1 = model1.to(DEVICE)\n",
        "\n",
        "# freeze encoder\n",
        "for param in model1.encoder.parameters():\n",
        "    param.requires_grad = False"
      ]
    },
    {
      "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
      "execution_count": null,
=======
      "source": [
        "train_clf(model=model1, epochs=N_EPOCHS, batch_size=BATCH_SIZE, train_loader=train_loader, lr=LR, device=DEVICE)"
      ],
>>>>>>> 88c8b7e (fine tuning strategies)
=======
      "execution_count": null,
>>>>>>> 3fd1e04 (clean files)
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0KhaLEPMK-xy",
        "outputId": "0202779b-8018-43d5-afdc-0bff387c3116"
      },
<<<<<<< HEAD
<<<<<<< HEAD
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
=======
      "execution_count": null,
=======
>>>>>>> 3fd1e04 (clean files)
      "outputs": [
        {
          "name": "stdout",
<<<<<<< HEAD
>>>>>>> 88c8b7e (fine tuning strategies)
=======
          "output_type": "stream",
>>>>>>> 3fd1e04 (clean files)
          "text": [
            "epoch 0 train loss 96.75105077028275\n",
            "epoch 1 train loss 82.85167887806892\n",
            "epoch 2 train loss 76.78185647726059\n",
            "epoch 3 train loss 73.41295690834522\n",
            "epoch 4 train loss 71.32681079208851\n",
            "epoch 5 train loss 69.34938235580921\n",
            "epoch 6 train loss 67.92075580358505\n",
            "epoch 7 train loss 65.6915245205164\n",
            "epoch 8 train loss 64.0440423488617\n",
            "epoch 9 train loss 62.470800653100014\n",
            "epoch 10 train loss 60.63560292124748\n",
            "epoch 11 train loss 58.99235409498215\n",
            "epoch 12 train loss 57.70361717045307\n",
            "epoch 13 train loss 56.13388539850712\n",
            "epoch 14 train loss 54.60328558087349\n",
            "epoch 15 train loss 53.588440611958504\n",
            "epoch 16 train loss 52.16248382627964\n",
            "epoch 17 train loss 51.70906560122967\n",
            "epoch 18 train loss 50.67980144917965\n",
            "epoch 19 train loss 49.854457914829254\n",
            "epoch 20 train loss 48.64652144908905\n",
            "epoch 21 train loss 48.43485701829195\n",
            "epoch 22 train loss 47.89348563551903\n",
            "epoch 23 train loss 47.477348893880844\n",
            "epoch 24 train loss 46.03241886943579\n",
            "epoch 25 train loss 46.11780732125044\n",
            "epoch 26 train loss 45.54881675541401\n",
            "epoch 27 train loss 44.327761210501194\n",
            "epoch 28 train loss 44.533193603158\n",
            "epoch 29 train loss 43.67095096409321\n"
          ]
        }
<<<<<<< HEAD
<<<<<<< HEAD
      ],
      "source": [
        "train_clf(model=model1, epochs=N_EPOCHS, batch_size=BATCH_SIZE, train_loader=train_loader, lr=LR, device=DEVICE)"
=======
>>>>>>> 88c8b7e (fine tuning strategies)
=======
      ],
      "source": [
        "train_clf(model=model1, epochs=N_EPOCHS, batch_size=BATCH_SIZE, train_loader=train_loader, lr=LR, device=DEVICE)"
>>>>>>> 3fd1e04 (clean files)
      ]
    },
    {
      "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
      "execution_count": null,
=======
      "source": [
        "y_pred = get_predictions(model1, test_loader)\n",
        "accuracy_score(y_pred, y_test), f1_score(y_pred, y_test), balanced_accuracy_score(y_pred, y_test)"
      ],
>>>>>>> 88c8b7e (fine tuning strategies)
=======
      "execution_count": null,
>>>>>>> 3fd1e04 (clean files)
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9P97xascSGb1",
        "outputId": "75e0414d-6af0-463c-ae95-7ca0306dcb58"
      },
<<<<<<< HEAD
<<<<<<< HEAD
      "outputs": [
        {
=======
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
>>>>>>> 88c8b7e (fine tuning strategies)
=======
      "outputs": [
        {
>>>>>>> 3fd1e04 (clean files)
          "data": {
            "text/plain": [
              "(0.9089659910683614, 0.9374262101534829, 0.8901142771745746)"
            ]
          },
<<<<<<< HEAD
<<<<<<< HEAD
          "execution_count": 171,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_pred = get_predictions(model1, test_loader)\n",
        "accuracy_score(y_pred, y_test), f1_score(y_pred, y_test), balanced_accuracy_score(y_pred, y_test)"
=======
=======
          "execution_count": 171,
>>>>>>> 3fd1e04 (clean files)
          "metadata": {},
          "output_type": "execute_result"
        }
<<<<<<< HEAD
>>>>>>> 88c8b7e (fine tuning strategies)
=======
      ],
      "source": [
        "y_pred = get_predictions(model1, test_loader)\n",
        "accuracy_score(y_pred, y_test), f1_score(y_pred, y_test), balanced_accuracy_score(y_pred, y_test)"
>>>>>>> 3fd1e04 (clean files)
      ]
    },
    {
      "cell_type": "markdown",
<<<<<<< HEAD
<<<<<<< HEAD
      "metadata": {
        "id": "6vTFQyC1G0jv"
      },
      "source": [
        "### 2 Train the entire model on the PTB dataset (encoder + output layers).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F4mK7xmWG3dU"
      },
      "outputs": [],
      "source": [
        "model2 = TimeSeriesClassifier(encoder=encoder, hidden_size=hidden_size, layer_sizes=[hidden_size, int(hidden_size/2)], dropout_prob=0.05)\n",
        "model2 = model2.to(DEVICE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
=======
      "source": [
        "### 2 Train the entire model on the PTB dataset (encoder + output layers).\n"
      ],
=======
>>>>>>> 3fd1e04 (clean files)
      "metadata": {
        "id": "6vTFQyC1G0jv"
      },
      "source": [
        "### 2 Train the entire model on the PTB dataset (encoder + output layers).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F4mK7xmWG3dU"
      },
      "outputs": [],
      "source": [
        "model2 = TimeSeriesClassifier(encoder=encoder, hidden_size=hidden_size, layer_sizes=[hidden_size, int(hidden_size/2)], dropout_prob=0.05)\n",
        "model2 = model2.to(DEVICE)"
      ]
    },
    {
      "cell_type": "code",
<<<<<<< HEAD
      "source": [
        "train_clf(model=model2, epochs=N_EPOCHS, batch_size=BATCH_SIZE, train_loader=train_loader, lr=LR, device=DEVICE)"
      ],
>>>>>>> 88c8b7e (fine tuning strategies)
=======
      "execution_count": null,
>>>>>>> 3fd1e04 (clean files)
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ugrwHZ4SkfS",
        "outputId": "334fad59-3959-4d38-9196-7ccb8221345a"
      },
<<<<<<< HEAD
<<<<<<< HEAD
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
=======
      "execution_count": null,
=======
>>>>>>> 3fd1e04 (clean files)
      "outputs": [
        {
          "name": "stdout",
<<<<<<< HEAD
>>>>>>> 88c8b7e (fine tuning strategies)
=======
          "output_type": "stream",
>>>>>>> 3fd1e04 (clean files)
          "text": [
            "epoch 0 train loss 93.90019416809082\n",
            "epoch 1 train loss 81.07586461305618\n",
            "epoch 2 train loss 75.7562313079834\n",
            "epoch 3 train loss 72.7193745970726\n",
            "epoch 4 train loss 70.04418049752712\n",
            "epoch 5 train loss 67.75436583161354\n",
            "epoch 6 train loss 65.6602114289999\n",
            "epoch 7 train loss 63.72325348854065\n",
            "epoch 8 train loss 62.15292306244373\n",
            "epoch 9 train loss 60.66056151688099\n",
            "epoch 10 train loss 59.041644752025604\n",
            "epoch 11 train loss 57.73614148795605\n",
            "epoch 12 train loss 56.61657218635082\n",
            "epoch 13 train loss 54.83641530573368\n",
            "epoch 14 train loss 53.98317164182663\n",
            "epoch 15 train loss 52.626456037163734\n",
            "epoch 16 train loss 52.05014856159687\n",
            "epoch 17 train loss 50.891385301947594\n",
            "epoch 18 train loss 49.78858503699303\n",
            "epoch 19 train loss 49.4273085296154\n",
            "epoch 20 train loss 48.27242286503315\n",
            "epoch 21 train loss 47.96456269919872\n",
            "epoch 22 train loss 47.34878271818161\n",
            "epoch 23 train loss 46.62107890844345\n",
            "epoch 24 train loss 45.81991498917341\n",
            "epoch 25 train loss 45.03987929970026\n",
            "epoch 26 train loss 45.10774323344231\n",
            "epoch 27 train loss 44.344491228461266\n",
            "epoch 28 train loss 43.20381759107113\n",
            "epoch 29 train loss 42.54516709595919\n"
          ]
        }
<<<<<<< HEAD
<<<<<<< HEAD
      ],
      "source": [
        "train_clf(model=model2, epochs=N_EPOCHS, batch_size=BATCH_SIZE, train_loader=train_loader, lr=LR, device=DEVICE)"
=======
>>>>>>> 88c8b7e (fine tuning strategies)
=======
      ],
      "source": [
        "train_clf(model=model2, epochs=N_EPOCHS, batch_size=BATCH_SIZE, train_loader=train_loader, lr=LR, device=DEVICE)"
>>>>>>> 3fd1e04 (clean files)
      ]
    },
    {
      "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
      "execution_count": null,
=======
      "source": [
        "y_pred = get_predictions(model2, test_loader)\n",
        "accuracy_score(y_pred, y_test), f1_score(y_pred, y_test), balanced_accuracy_score(y_pred, y_test)"
      ],
>>>>>>> 88c8b7e (fine tuning strategies)
=======
      "execution_count": null,
>>>>>>> 3fd1e04 (clean files)
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bYdM8D0hSodj",
        "outputId": "a9490146-d021-47d4-da4b-de953c568bea"
      },
<<<<<<< HEAD
<<<<<<< HEAD
      "outputs": [
        {
=======
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
>>>>>>> 88c8b7e (fine tuning strategies)
=======
      "outputs": [
        {
>>>>>>> 3fd1e04 (clean files)
          "data": {
            "text/plain": [
              "(0.9089659910683614, 0.9365877004067958, 0.8841817253948405)"
            ]
          },
<<<<<<< HEAD
<<<<<<< HEAD
          "execution_count": 174,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_pred = get_predictions(model2, test_loader)\n",
        "accuracy_score(y_pred, y_test), f1_score(y_pred, y_test), balanced_accuracy_score(y_pred, y_test)"
=======
=======
          "execution_count": 174,
>>>>>>> 3fd1e04 (clean files)
          "metadata": {},
          "output_type": "execute_result"
        }
<<<<<<< HEAD
>>>>>>> 88c8b7e (fine tuning strategies)
=======
      ],
      "source": [
        "y_pred = get_predictions(model2, test_loader)\n",
        "accuracy_score(y_pred, y_test), f1_score(y_pred, y_test), balanced_accuracy_score(y_pred, y_test)"
>>>>>>> 3fd1e04 (clean files)
      ]
    },
    {
      "cell_type": "markdown",
<<<<<<< HEAD
<<<<<<< HEAD
      "metadata": {
        "id": "pG6sXUZnSbjE"
      },
      "source": [
        "### 3 First, train the output layers, then unfreeze and train the entire joint model in two separate stages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1vFUaE74Sdxe"
      },
      "outputs": [],
=======
      "source": [
        "### 3 First, train the output layers, then unfreeze and train the entire joint model in two separate stages."
      ],
=======
>>>>>>> 3fd1e04 (clean files)
      "metadata": {
        "id": "pG6sXUZnSbjE"
      },
      "source": [
        "### 3 First, train the output layers, then unfreeze and train the entire joint model in two separate stages."
      ]
    },
    {
      "cell_type": "code",
<<<<<<< HEAD
>>>>>>> 88c8b7e (fine tuning strategies)
=======
      "execution_count": null,
      "metadata": {
        "id": "1vFUaE74Sdxe"
      },
      "outputs": [],
>>>>>>> 3fd1e04 (clean files)
      "source": [
        "model3 = TimeSeriesClassifier(encoder=encoder, hidden_size=hidden_size, layer_sizes=[hidden_size, int(hidden_size/2)], dropout_prob=0.05)\n",
        "model3 = model3.to(DEVICE)\n",
        "\n",
        "# freeze encoder\n",
        "for param in model3.encoder.parameters():\n",
        "    param.requires_grad = False"
<<<<<<< HEAD
<<<<<<< HEAD
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
=======
      ],
      "metadata": {
        "id": "1vFUaE74Sdxe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_clf(model=model3, epochs=N_EPOCHS, batch_size=BATCH_SIZE, train_loader=train_loader, lr=LR, device=DEVICE)"
      ],
>>>>>>> 88c8b7e (fine tuning strategies)
=======
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
>>>>>>> 3fd1e04 (clean files)
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6i98O6-RTDrx",
        "outputId": "fd02f89c-6a03-4d78-da9d-cea93d7b4275"
      },
<<<<<<< HEAD
<<<<<<< HEAD
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
=======
      "execution_count": null,
=======
>>>>>>> 3fd1e04 (clean files)
      "outputs": [
        {
          "name": "stdout",
<<<<<<< HEAD
>>>>>>> 88c8b7e (fine tuning strategies)
=======
          "output_type": "stream",
>>>>>>> 3fd1e04 (clean files)
          "text": [
            "epoch 0 train loss 94.42457100749016\n",
            "epoch 1 train loss 79.47241824865341\n",
            "epoch 2 train loss 74.53904396295547\n",
            "epoch 3 train loss 71.53491115570068\n",
            "epoch 4 train loss 69.51486666500568\n",
            "epoch 5 train loss 67.66246801614761\n",
            "epoch 6 train loss 65.78127066791058\n",
            "epoch 7 train loss 64.057232812047\n",
            "epoch 8 train loss 62.46819940209389\n",
            "epoch 9 train loss 61.24090501666069\n",
            "epoch 10 train loss 60.1319864243269\n",
            "epoch 11 train loss 58.83323009312153\n",
            "epoch 12 train loss 58.01156145334244\n",
            "epoch 13 train loss 56.44874532520771\n",
            "epoch 14 train loss 55.8611836284399\n",
            "epoch 15 train loss 54.71998347342014\n",
            "epoch 16 train loss 54.296542167663574\n",
            "epoch 17 train loss 53.40027917921543\n",
            "epoch 18 train loss 52.50051248073578\n",
            "epoch 19 train loss 51.83314363658428\n",
            "epoch 20 train loss 50.68542338907719\n",
            "epoch 21 train loss 50.211225643754005\n",
            "epoch 22 train loss 49.482344046235085\n",
            "epoch 23 train loss 48.64254926145077\n",
            "epoch 24 train loss 47.87079732120037\n",
            "epoch 25 train loss 47.70423060655594\n",
            "epoch 26 train loss 47.06355136632919\n",
            "epoch 27 train loss 46.32133939862251\n",
            "epoch 28 train loss 45.66360566020012\n",
            "epoch 29 train loss 44.67454679310322\n"
          ]
        }
<<<<<<< HEAD
<<<<<<< HEAD
      ],
      "source": [
        "train_clf(model=model3, epochs=N_EPOCHS, batch_size=BATCH_SIZE, train_loader=train_loader, lr=LR, device=DEVICE)"
=======
>>>>>>> 88c8b7e (fine tuning strategies)
=======
      ],
      "source": [
        "train_clf(model=model3, epochs=N_EPOCHS, batch_size=BATCH_SIZE, train_loader=train_loader, lr=LR, device=DEVICE)"
>>>>>>> 3fd1e04 (clean files)
      ]
    },
    {
      "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
      "execution_count": null,
=======
      "source": [
        "# unfreeze encoder\n",
        "for param in model3.encoder.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "train_clf(model=model3, epochs=N_EPOCHS, batch_size=BATCH_SIZE, train_loader=train_loader, lr=LR, device=DEVICE)"
      ],
>>>>>>> 88c8b7e (fine tuning strategies)
=======
      "execution_count": null,
>>>>>>> 3fd1e04 (clean files)
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kIk2ndscTFxr",
        "outputId": "634b16b0-fb2c-4944-c64d-8525e2a79165"
      },
<<<<<<< HEAD
<<<<<<< HEAD
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
=======
      "execution_count": null,
=======
>>>>>>> 3fd1e04 (clean files)
      "outputs": [
        {
          "name": "stdout",
<<<<<<< HEAD
>>>>>>> 88c8b7e (fine tuning strategies)
=======
          "output_type": "stream",
>>>>>>> 3fd1e04 (clean files)
          "text": [
            "epoch 0 train loss 43.77062365412712\n",
            "epoch 1 train loss 39.25150250643492\n",
            "epoch 2 train loss 36.64535838365555\n",
            "epoch 3 train loss 34.47888941317797\n",
            "epoch 4 train loss 33.02504141628742\n",
            "epoch 5 train loss 30.55866066366434\n",
            "epoch 6 train loss 29.768264915794134\n",
            "epoch 7 train loss 28.224283169955015\n",
            "epoch 8 train loss 25.375430420041084\n",
            "epoch 9 train loss 25.268023643642664\n",
            "epoch 10 train loss 24.12083588168025\n",
            "epoch 11 train loss 23.509501680731773\n",
            "epoch 12 train loss 22.748831935226917\n",
            "epoch 13 train loss 21.27926165983081\n",
            "epoch 14 train loss 20.231194971129298\n",
            "epoch 15 train loss 20.172702809795737\n",
            "epoch 16 train loss 19.447189010679722\n",
            "epoch 17 train loss 18.060569409281015\n",
            "epoch 18 train loss 17.55083186738193\n",
            "epoch 19 train loss 17.16678594239056\n",
            "epoch 20 train loss 17.135951979085803\n",
            "epoch 21 train loss 15.627752775326371\n",
            "epoch 22 train loss 15.311705376952887\n",
            "epoch 23 train loss 15.306591225787997\n",
            "epoch 24 train loss 14.94433636777103\n",
            "epoch 25 train loss 14.0496222153306\n",
            "epoch 26 train loss 14.096208835020661\n",
            "epoch 27 train loss 13.857134777121246\n",
            "epoch 28 train loss 13.263767438940704\n",
            "epoch 29 train loss 12.783194636926055\n"
          ]
        }
<<<<<<< HEAD
<<<<<<< HEAD
=======
>>>>>>> 3fd1e04 (clean files)
      ],
      "source": [
        "# unfreeze encoder\n",
        "for param in model3.encoder.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "train_clf(model=model3, epochs=N_EPOCHS, batch_size=BATCH_SIZE, train_loader=train_loader, lr=LR, device=DEVICE)"
<<<<<<< HEAD
=======
>>>>>>> 88c8b7e (fine tuning strategies)
=======
>>>>>>> 3fd1e04 (clean files)
      ]
    },
    {
      "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
      "execution_count": null,
=======
      "source": [
        "y_pred = get_predictions(model3, test_loader)\n",
        "accuracy_score(y_pred, y_test), f1_score(y_pred, y_test), balanced_accuracy_score(y_pred, y_test)"
      ],
>>>>>>> 88c8b7e (fine tuning strategies)
=======
      "execution_count": null,
>>>>>>> 3fd1e04 (clean files)
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dEklDtHeTS-B",
        "outputId": "150a8831-deab-4fc7-f6f6-42b07e9f8135"
      },
<<<<<<< HEAD
<<<<<<< HEAD
      "outputs": [
        {
=======
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
>>>>>>> 88c8b7e (fine tuning strategies)
=======
      "outputs": [
        {
>>>>>>> 3fd1e04 (clean files)
          "data": {
            "text/plain": [
              "(0.9725180350395053, 0.9810066476733144, 0.9671015496032802)"
            ]
          },
<<<<<<< HEAD
<<<<<<< HEAD
          "execution_count": 178,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_pred = get_predictions(model3, test_loader)\n",
        "accuracy_score(y_pred, y_test), f1_score(y_pred, y_test), balanced_accuracy_score(y_pred, y_test)"
=======
=======
          "execution_count": 178,
>>>>>>> 3fd1e04 (clean files)
          "metadata": {},
          "output_type": "execute_result"
        }
<<<<<<< HEAD
>>>>>>> 88c8b7e (fine tuning strategies)
=======
      ],
      "source": [
        "y_pred = get_predictions(model3, test_loader)\n",
        "accuracy_score(y_pred, y_test), f1_score(y_pred, y_test), balanced_accuracy_score(y_pred, y_test)"
>>>>>>> 3fd1e04 (clean files)
      ]
    }
  ],
  "metadata": {
<<<<<<< HEAD
<<<<<<< HEAD
=======
    "language_info": {
      "name": "python"
    },
>>>>>>> 88c8b7e (fine tuning strategies)
=======
>>>>>>> 3fd1e04 (clean files)
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
<<<<<<< HEAD
<<<<<<< HEAD
=======
>>>>>>> 3fd1e04 (clean files)
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
<<<<<<< HEAD
=======
      "name": "python3",
      "display_name": "Python 3"
>>>>>>> 88c8b7e (fine tuning strategies)
=======
>>>>>>> 3fd1e04 (clean files)
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
<<<<<<< HEAD
<<<<<<< HEAD
}
=======
}
>>>>>>> 88c8b7e (fine tuning strategies)
=======
}
>>>>>>> 3fd1e04 (clean files)
