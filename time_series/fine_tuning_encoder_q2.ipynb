{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import multiprocessing\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch import optim\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import accuracy_score, f1_score, balanced_accuracy_score\n",
        "from lightgbm import LGBMClassifier\n",
        "from tqdm import tqdm\n",
        "from torch.utils.data import Dataset, DataLoader, TensorDataset"
      ],
      "metadata": {
        "id": "2sJWPWow9SXF"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y008k8oI85X0",
        "outputId": "cb7253cd-1eb5-4309-ae6e-c7b8d5da6329"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir(\"/gdrive/MyDrive/ml-for-healthcare\")"
      ],
      "metadata": {
        "id": "YzPKOi139VDu"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from encoder import AutoEncoderCnn"
      ],
      "metadata": {
        "id": "C4nwljn51wxw"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "HJT0iuIW-9Ua"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IxGUtYNR8MDr"
      },
      "source": [
        "# Q4: Finetuning Strategies using Encoder from Q2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s7m76Gt58MDu"
      },
      "source": [
        "## 1. Classic ML\n",
        "Similar to Q3,\n",
        "- obtain representations for the PTB dataset by feeding the dataset through the pre-trained encoder\n",
        "- Use a classic ML method from Part 1 to train and test for the PTB task using these representations"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Encode dataset"
      ],
      "metadata": {
        "id": "0vvr57tk9pWi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load data\n",
        "train = pd.read_csv(\"ptbdb_train.csv\", header=None)\n",
        "test = pd.read_csv(\"ptbdb_test.csv\", header=None)\n",
        "\n",
        "X_train = train.drop(187, axis=1)\n",
        "X_test = test.drop(187, axis=1)\n",
        "\n",
        "y_train = train[187]\n",
        "y_test = test[187]"
      ],
      "metadata": {
        "id": "Q9oCJsU797yf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load autoencoder model\n",
        "ae = AutoEncoderCnn()\n",
        "ae.to(DEVICE)\n",
        "ae.load_state_dict(torch.load(\"encoder_model.pth\"))"
      ],
      "metadata": {
        "id": "6utNGyAz9ojJ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# feed data through encoder model to get embeddings\n",
        "\n",
        "def get_encodings(model, X, device, batchsize=64):\n",
        "  X_tensor = torch.tensor(X.values, dtype=torch.float32)\n",
        "  X_dataloader = DataLoader(X_tensor, batch_size=batchsize, shuffle=False)\n",
        "\n",
        "  encodings = []\n",
        "\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    for x_batch in X_dataloader:\n",
        "      x_batch = x_batch.unsqueeze(1)\n",
        "      x_batch = x_batch.to(device)\n",
        "      x_batch_encoding = model(x_batch)\n",
        "      encodings.append(x_batch_encoding.detach().cpu().numpy())\n",
        "\n",
        "  return encodings\n",
        "\n",
        "encoder = ae.encoder\n",
        "X_train_encodings = get_encodings(model=encoder, X=X_train, device=DEVICE)\n",
        "X_test_encodings = get_encodings(model=encoder, X=X_test, device=DEVICE)"
      ],
      "metadata": {
        "id": "VccPXDJ595iP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create numpy matrices from list of batches\n",
        "X_train_encodings = np.vstack(X_train_encodings)\n",
        "X_test_encodings = np.vstack(X_test_encodings)"
      ],
      "metadata": {
        "id": "unFlPfY2DGu8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train and Test classic ML model"
      ],
      "metadata": {
        "id": "b3zOLOP19zVh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "collapsed": true,
        "id": "m4IFsOje8MDu",
        "outputId": "ef9d5821-d61d-4d74-a483-17500e3d8eae"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LGBMClassifier(max_depth=9, n_estimators=500, verbose=-1)"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMClassifier(max_depth=9, n_estimators=500, verbose=-1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(max_depth=9, n_estimators=500, verbose=-1)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 155
        }
      ],
      "source": [
        "# train classic ML model\n",
        "clf = LGBMClassifier(verbose=-1, n_estimators=500, learning_rate=0.1, max_depth=9) # choose parameters from part 1\n",
        "clf.fit(X_train_encodings, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test performance\n",
        "y_pred = clf.predict(X_test_encodings)\n",
        "accuracy_score(y_pred, y_test), f1_score(y_pred, y_test), balanced_accuracy_score(y_pred, y_test)"
      ],
      "metadata": {
        "id": "xOvbYuSzbsvz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train classic ML model\n",
        "param_grid = {'n_estimators': [100, 200, 300, 400, 500],\n",
        "              'learning_rate': [0.01, 0.1, 1],\n",
        "              'max_depth': [3, 5, 7, 9]}\n",
        "\n",
        "clf = LGBMClassifier(verbose=-1)\n",
        "\n",
        "grid_search = GridSearchCV(clf, param_grid, cv=5, scoring='f1')\n",
        "grid_search.fit(X_train_encodings, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 116
        },
        "id": "YAdhKQqOXpwz",
        "outputId": "4b635986-8789-489d-f1bd-a6ebd1c12c26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, estimator=LGBMClassifier(verbose=-1),\n",
              "             param_grid={'learning_rate': [0.01, 0.1, 1],\n",
              "                         'max_depth': [3, 5, 7, 9],\n",
              "                         'n_estimators': [100, 200, 300, 400, 500]},\n",
              "             scoring='f1')"
            ],
            "text/html": [
              "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=LGBMClassifier(verbose=-1),\n",
              "             param_grid={&#x27;learning_rate&#x27;: [0.01, 0.1, 1],\n",
              "                         &#x27;max_depth&#x27;: [3, 5, 7, 9],\n",
              "                         &#x27;n_estimators&#x27;: [100, 200, 300, 400, 500]},\n",
              "             scoring=&#x27;f1&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=LGBMClassifier(verbose=-1),\n",
              "             param_grid={&#x27;learning_rate&#x27;: [0.01, 0.1, 1],\n",
              "                         &#x27;max_depth&#x27;: [3, 5, 7, 9],\n",
              "                         &#x27;n_estimators&#x27;: [100, 200, 300, 400, 500]},\n",
              "             scoring=&#x27;f1&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(verbose=-1)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(verbose=-1)</pre></div></div></div></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 165
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Best parameters: {}\".format(grid_search.best_params_))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g2QB1JoReIq9",
        "outputId": "6bb23e0d-d491-404f-ff07-683f44088518"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters: {'learning_rate': 0.1, 'max_depth': 9, 'n_estimators': 500}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test performance\n",
        "y_pred = grid_search.predict(X_test_encodings)\n",
        "accuracy_score(y_pred, y_test), f1_score(y_pred, y_test), balanced_accuracy_score(y_pred, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kd8OPEoU-EY8",
        "outputId": "4b358b82-9d88-4954-ddde-9aea4e4e6dba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.971830985915493, 0.9805410536307546, 0.9665816882845981)"
            ]
          },
          "metadata": {},
          "execution_count": 166
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0KCyZnYX8MDw"
      },
      "source": [
        "## 2. ANNs\n",
        "Add output layer(s) for the PTB binary class to your encoder model. Implement the following finetuning strategies\n",
        "- Train the output layer(s) only on the PTB dataset, freezing the encoder\n",
        "- Train the entire model on the PTB dataset (encoder + output layers).\n",
        "- First, train the output layers, then unfreeze and train the entire joint model in two\n",
        "separate stages."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Add output layer(s) for the PTB binary class to your encoder model."
      ],
      "metadata": {
        "id": "ZZKUMssfG8pA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TimeSeriesClassifier(torch.nn.Module):\n",
        "  def __init__(self, encoder, hidden_size, layer_sizes, dropout_prob):\n",
        "    super(TimeSeriesClassifier, self).__init__()\n",
        "    self.encoder = encoder\n",
        "    self.classifier = torch.nn.Sequential(\n",
        "        torch.nn.Linear(hidden_size, layer_sizes[0]),\n",
        "        torch.nn.ReLU(),\n",
        "        torch.nn.Dropout(dropout_prob),\n",
        "        torch.nn.Linear(layer_sizes[0], layer_sizes[1]),\n",
        "        torch.nn.ReLU(),\n",
        "        torch.nn.Dropout(dropout_prob),\n",
        "        torch.nn.Linear(layer_sizes[1], 1),\n",
        "        torch.nn.Sigmoid()\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.classifier(self.encoder(x))"
      ],
      "metadata": {
        "id": "94mCzbnAG7pk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_clf(model, epochs, batch_size, train_loader, lr, device):\n",
        "  criterion = torch.nn.BCELoss()\n",
        "  optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "\n",
        "      model.train()\n",
        "\n",
        "      epoch_loss = 0\n",
        "\n",
        "      for X, y in train_loader:\n",
        "\n",
        "          X = X.to(DEVICE)\n",
        "          y = y.to(DEVICE)\n",
        "\n",
        "          y_pred = model(X.unsqueeze(1))\n",
        "\n",
        "          # loss = criterion(y_pred, batch[\"score\"])\n",
        "          loss = criterion(y_pred.squeeze(1), y)\n",
        "\n",
        "          # backward pass\n",
        "          optimizer.zero_grad()\n",
        "          loss.backward()\n",
        "\n",
        "          # update weights\n",
        "          optimizer.step()\n",
        "\n",
        "          epoch_loss += loss.item()\n",
        "\n",
        "      print(f\"epoch {epoch} train loss {epoch_loss}\")"
      ],
      "metadata": {
        "id": "L1kaYlTPLFo5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_predictions(model, test_loader):\n",
        "  y_preds = []\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    for X, y in test_loader:\n",
        "      X = X.to(DEVICE)\n",
        "      y = y.to(DEVICE)\n",
        "      y_pred = model(X.unsqueeze(1))\n",
        "      y_preds.append(y_pred.detach().cpu().numpy())\n",
        "  return np.round(np.vstack(y_preds))"
      ],
      "metadata": {
        "id": "t__9qS3cQn7q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = TensorDataset(torch.tensor(X_train.to_numpy(), dtype=torch.float32), torch.tensor(y_train, dtype=torch.float32))\n",
        "test_dataset = TensorDataset(torch.tensor(X_test.to_numpy(), dtype=torch.float32), torch.tensor(y_test, dtype=torch.float32))\n",
        "\n",
        "BATCH_SIZE = 64\n",
        "train_loader = DataLoader(train_dataset, shuffle=False, batch_size=BATCH_SIZE, pin_memory=True)\n",
        "test_loader = DataLoader(test_dataset, shuffle=False, batch_size=BATCH_SIZE, pin_memory=True)"
      ],
      "metadata": {
        "id": "oPnTZhF7NZAP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "N_EPOCHS = 30\n",
        "LR = 0.0003\n",
        "hidden_size = 128 # bottleneck dimension of encoder"
      ],
      "metadata": {
        "id": "_V3dR33vPWJ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1 Train the output layer(s) only on the PTB dataset, freezing the encoder"
      ],
      "metadata": {
        "id": "CZvhU1RYGuR9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "3i5Ki0Fw8MDx"
      },
      "outputs": [],
      "source": [
        "model1 = TimeSeriesClassifier(encoder=encoder, hidden_size=hidden_size, layer_sizes=[hidden_size, int(hidden_size/2)], dropout_prob=0.05)\n",
        "model1 = model1.to(DEVICE)\n",
        "\n",
        "# freeze encoder\n",
        "for param in model1.encoder.parameters():\n",
        "    param.requires_grad = False"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_clf(model=model1, epochs=N_EPOCHS, batch_size=BATCH_SIZE, train_loader=train_loader, lr=LR, device=DEVICE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0KhaLEPMK-xy",
        "outputId": "0202779b-8018-43d5-afdc-0bff387c3116"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0 train loss 96.75105077028275\n",
            "epoch 1 train loss 82.85167887806892\n",
            "epoch 2 train loss 76.78185647726059\n",
            "epoch 3 train loss 73.41295690834522\n",
            "epoch 4 train loss 71.32681079208851\n",
            "epoch 5 train loss 69.34938235580921\n",
            "epoch 6 train loss 67.92075580358505\n",
            "epoch 7 train loss 65.6915245205164\n",
            "epoch 8 train loss 64.0440423488617\n",
            "epoch 9 train loss 62.470800653100014\n",
            "epoch 10 train loss 60.63560292124748\n",
            "epoch 11 train loss 58.99235409498215\n",
            "epoch 12 train loss 57.70361717045307\n",
            "epoch 13 train loss 56.13388539850712\n",
            "epoch 14 train loss 54.60328558087349\n",
            "epoch 15 train loss 53.588440611958504\n",
            "epoch 16 train loss 52.16248382627964\n",
            "epoch 17 train loss 51.70906560122967\n",
            "epoch 18 train loss 50.67980144917965\n",
            "epoch 19 train loss 49.854457914829254\n",
            "epoch 20 train loss 48.64652144908905\n",
            "epoch 21 train loss 48.43485701829195\n",
            "epoch 22 train loss 47.89348563551903\n",
            "epoch 23 train loss 47.477348893880844\n",
            "epoch 24 train loss 46.03241886943579\n",
            "epoch 25 train loss 46.11780732125044\n",
            "epoch 26 train loss 45.54881675541401\n",
            "epoch 27 train loss 44.327761210501194\n",
            "epoch 28 train loss 44.533193603158\n",
            "epoch 29 train loss 43.67095096409321\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = get_predictions(model1, test_loader)\n",
        "accuracy_score(y_pred, y_test), f1_score(y_pred, y_test), balanced_accuracy_score(y_pred, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9P97xascSGb1",
        "outputId": "75e0414d-6af0-463c-ae95-7ca0306dcb58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.9089659910683614, 0.9374262101534829, 0.8901142771745746)"
            ]
          },
          "metadata": {},
          "execution_count": 171
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2 Train the entire model on the PTB dataset (encoder + output layers).\n"
      ],
      "metadata": {
        "id": "6vTFQyC1G0jv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = TimeSeriesClassifier(encoder=encoder, hidden_size=hidden_size, layer_sizes=[hidden_size, int(hidden_size/2)], dropout_prob=0.05)\n",
        "model2 = model2.to(DEVICE)"
      ],
      "metadata": {
        "id": "F4mK7xmWG3dU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_clf(model=model2, epochs=N_EPOCHS, batch_size=BATCH_SIZE, train_loader=train_loader, lr=LR, device=DEVICE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ugrwHZ4SkfS",
        "outputId": "334fad59-3959-4d38-9196-7ccb8221345a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0 train loss 93.90019416809082\n",
            "epoch 1 train loss 81.07586461305618\n",
            "epoch 2 train loss 75.7562313079834\n",
            "epoch 3 train loss 72.7193745970726\n",
            "epoch 4 train loss 70.04418049752712\n",
            "epoch 5 train loss 67.75436583161354\n",
            "epoch 6 train loss 65.6602114289999\n",
            "epoch 7 train loss 63.72325348854065\n",
            "epoch 8 train loss 62.15292306244373\n",
            "epoch 9 train loss 60.66056151688099\n",
            "epoch 10 train loss 59.041644752025604\n",
            "epoch 11 train loss 57.73614148795605\n",
            "epoch 12 train loss 56.61657218635082\n",
            "epoch 13 train loss 54.83641530573368\n",
            "epoch 14 train loss 53.98317164182663\n",
            "epoch 15 train loss 52.626456037163734\n",
            "epoch 16 train loss 52.05014856159687\n",
            "epoch 17 train loss 50.891385301947594\n",
            "epoch 18 train loss 49.78858503699303\n",
            "epoch 19 train loss 49.4273085296154\n",
            "epoch 20 train loss 48.27242286503315\n",
            "epoch 21 train loss 47.96456269919872\n",
            "epoch 22 train loss 47.34878271818161\n",
            "epoch 23 train loss 46.62107890844345\n",
            "epoch 24 train loss 45.81991498917341\n",
            "epoch 25 train loss 45.03987929970026\n",
            "epoch 26 train loss 45.10774323344231\n",
            "epoch 27 train loss 44.344491228461266\n",
            "epoch 28 train loss 43.20381759107113\n",
            "epoch 29 train loss 42.54516709595919\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = get_predictions(model2, test_loader)\n",
        "accuracy_score(y_pred, y_test), f1_score(y_pred, y_test), balanced_accuracy_score(y_pred, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bYdM8D0hSodj",
        "outputId": "a9490146-d021-47d4-da4b-de953c568bea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.9089659910683614, 0.9365877004067958, 0.8841817253948405)"
            ]
          },
          "metadata": {},
          "execution_count": 174
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3 First, train the output layers, then unfreeze and train the entire joint model in two separate stages."
      ],
      "metadata": {
        "id": "pG6sXUZnSbjE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model3 = TimeSeriesClassifier(encoder=encoder, hidden_size=hidden_size, layer_sizes=[hidden_size, int(hidden_size/2)], dropout_prob=0.05)\n",
        "model3 = model3.to(DEVICE)\n",
        "\n",
        "# freeze encoder\n",
        "for param in model3.encoder.parameters():\n",
        "    param.requires_grad = False"
      ],
      "metadata": {
        "id": "1vFUaE74Sdxe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_clf(model=model3, epochs=N_EPOCHS, batch_size=BATCH_SIZE, train_loader=train_loader, lr=LR, device=DEVICE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6i98O6-RTDrx",
        "outputId": "fd02f89c-6a03-4d78-da9d-cea93d7b4275"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0 train loss 94.42457100749016\n",
            "epoch 1 train loss 79.47241824865341\n",
            "epoch 2 train loss 74.53904396295547\n",
            "epoch 3 train loss 71.53491115570068\n",
            "epoch 4 train loss 69.51486666500568\n",
            "epoch 5 train loss 67.66246801614761\n",
            "epoch 6 train loss 65.78127066791058\n",
            "epoch 7 train loss 64.057232812047\n",
            "epoch 8 train loss 62.46819940209389\n",
            "epoch 9 train loss 61.24090501666069\n",
            "epoch 10 train loss 60.1319864243269\n",
            "epoch 11 train loss 58.83323009312153\n",
            "epoch 12 train loss 58.01156145334244\n",
            "epoch 13 train loss 56.44874532520771\n",
            "epoch 14 train loss 55.8611836284399\n",
            "epoch 15 train loss 54.71998347342014\n",
            "epoch 16 train loss 54.296542167663574\n",
            "epoch 17 train loss 53.40027917921543\n",
            "epoch 18 train loss 52.50051248073578\n",
            "epoch 19 train loss 51.83314363658428\n",
            "epoch 20 train loss 50.68542338907719\n",
            "epoch 21 train loss 50.211225643754005\n",
            "epoch 22 train loss 49.482344046235085\n",
            "epoch 23 train loss 48.64254926145077\n",
            "epoch 24 train loss 47.87079732120037\n",
            "epoch 25 train loss 47.70423060655594\n",
            "epoch 26 train loss 47.06355136632919\n",
            "epoch 27 train loss 46.32133939862251\n",
            "epoch 28 train loss 45.66360566020012\n",
            "epoch 29 train loss 44.67454679310322\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# unfreeze encoder\n",
        "for param in model3.encoder.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "train_clf(model=model3, epochs=N_EPOCHS, batch_size=BATCH_SIZE, train_loader=train_loader, lr=LR, device=DEVICE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kIk2ndscTFxr",
        "outputId": "634b16b0-fb2c-4944-c64d-8525e2a79165"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0 train loss 43.77062365412712\n",
            "epoch 1 train loss 39.25150250643492\n",
            "epoch 2 train loss 36.64535838365555\n",
            "epoch 3 train loss 34.47888941317797\n",
            "epoch 4 train loss 33.02504141628742\n",
            "epoch 5 train loss 30.55866066366434\n",
            "epoch 6 train loss 29.768264915794134\n",
            "epoch 7 train loss 28.224283169955015\n",
            "epoch 8 train loss 25.375430420041084\n",
            "epoch 9 train loss 25.268023643642664\n",
            "epoch 10 train loss 24.12083588168025\n",
            "epoch 11 train loss 23.509501680731773\n",
            "epoch 12 train loss 22.748831935226917\n",
            "epoch 13 train loss 21.27926165983081\n",
            "epoch 14 train loss 20.231194971129298\n",
            "epoch 15 train loss 20.172702809795737\n",
            "epoch 16 train loss 19.447189010679722\n",
            "epoch 17 train loss 18.060569409281015\n",
            "epoch 18 train loss 17.55083186738193\n",
            "epoch 19 train loss 17.16678594239056\n",
            "epoch 20 train loss 17.135951979085803\n",
            "epoch 21 train loss 15.627752775326371\n",
            "epoch 22 train loss 15.311705376952887\n",
            "epoch 23 train loss 15.306591225787997\n",
            "epoch 24 train loss 14.94433636777103\n",
            "epoch 25 train loss 14.0496222153306\n",
            "epoch 26 train loss 14.096208835020661\n",
            "epoch 27 train loss 13.857134777121246\n",
            "epoch 28 train loss 13.263767438940704\n",
            "epoch 29 train loss 12.783194636926055\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = get_predictions(model3, test_loader)\n",
        "accuracy_score(y_pred, y_test), f1_score(y_pred, y_test), balanced_accuracy_score(y_pred, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dEklDtHeTS-B",
        "outputId": "150a8831-deab-4fc7-f6f6-42b07e9f8135"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.9725180350395053, 0.9810066476733144, 0.9671015496032802)"
            ]
          },
          "metadata": {},
          "execution_count": 178
        }
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}